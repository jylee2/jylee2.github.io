[
  {
    "id": 1,
    "question": "What is the difference between an Array and a Linked List?",
    "answer": "**Array:**\n- Contiguous memory allocation\n- Fixed size (in most languages) or dynamic with reallocation\n- O(1) random access by index\n- O(n) insertion/deletion (shifting elements)\n- Cache-friendly due to locality\n\n**Linked List:**\n- Non-contiguous memory (nodes with pointers)\n- Dynamic size, grows/shrinks easily\n- O(n) access (must traverse)\n- O(1) insertion/deletion (if you have the node reference)\n- Extra memory for pointers\n\n**When to use Array:**\n- Frequent random access\n- Known or fixed size\n- Memory efficiency matters\n\n**When to use Linked List:**\n- Frequent insertions/deletions\n- Unknown size, dynamic growth\n- No need for random access",
    "example": "// Array - O(1) access, O(n) insert at beginning\nint[] arr = {1, 2, 3, 4, 5};\nint value = arr[2];  // O(1) - direct access\n// Insert at beginning requires shifting all elements\n\n// Linked List - O(n) access, O(1) insert at beginning\nclass Node {\n    int val;\n    Node next;\n}\n\n// Access element at index 2 - must traverse\nNode current = head;\nfor (int i = 0; i < 2; i++) {\n    current = current.next;  // O(n)\n}\n\n// Insert at beginning - just update pointers\nNode newNode = new Node(0);\nnewNode.next = head;  // O(1)\nhead = newNode;\n\n// Time Complexity Comparison:\n// Operation      | Array | Linked List\n// Access         | O(1)  | O(n)\n// Search         | O(n)  | O(n)\n// Insert (begin) | O(n)  | O(1)\n// Insert (end)   | O(1)* | O(1) with tail pointer\n// Delete         | O(n)  | O(1) if node known"
  },
  {
    "id": 2,
    "question": "What is Big O notation and what are common time complexities?",
    "answer": "**Big O notation** describes the upper bound of an algorithm's time or space complexity as input size grows.\n\n**Common time complexities (best to worst):**\n\n- **O(1)** - Constant: Hash table lookup, array access\n- **O(log n)** - Logarithmic: Binary search, balanced BST operations\n- **O(n)** - Linear: Linear search, single loop\n- **O(n log n)** - Linearithmic: Merge sort, quick sort (average)\n- **O(n²)** - Quadratic: Bubble sort, nested loops\n- **O(2ⁿ)** - Exponential: Recursive fibonacci, subsets\n- **O(n!)** - Factorial: Permutations, traveling salesman brute force\n\n**Key concepts:**\n- Drop constants: O(2n) → O(n)\n- Drop lower terms: O(n² + n) → O(n²)\n- Worst case is typically used\n- Big Omega (Ω) is lower bound, Big Theta (Θ) is tight bound",
    "example": "// O(1) - Constant\nint getFirst(int[] arr) {\n    return arr[0];  // Always one operation\n}\n\n// O(log n) - Logarithmic\nint binarySearch(int[] arr, int target) {\n    int left = 0, right = arr.length - 1;\n    while (left <= right) {\n        int mid = (left + right) / 2;\n        if (arr[mid] == target) return mid;\n        if (arr[mid] < target) left = mid + 1;\n        else right = mid - 1;\n    }  // Halves search space each iteration\n    return -1;\n}\n\n// O(n) - Linear\nint sum(int[] arr) {\n    int total = 0;\n    for (int num : arr) total += num;  // Visit each once\n    return total;\n}\n\n// O(n²) - Quadratic\nvoid printPairs(int[] arr) {\n    for (int i = 0; i < arr.length; i++) {\n        for (int j = 0; j < arr.length; j++) {\n            System.out.println(arr[i] + \",\" + arr[j]);\n        }  // Nested loops over same array\n    }\n}"
  },
  {
    "id": 3,
    "question": "How does a Hash Table work and how are collisions handled?",
    "answer": "**Hash Table** stores key-value pairs using a hash function to compute an index.\n\n**How it works:**\n1. Hash function converts key to integer\n2. Index = hash % array_size\n3. Store value at computed index\n4. Average O(1) for insert, lookup, delete\n\n**Collision handling methods:**\n\n**Chaining (Separate Chaining):**\n- Each bucket contains a linked list\n- Colliding elements added to the list\n- Simple but uses extra memory\n\n**Open Addressing:**\n- Find next available slot in array\n- Linear probing: check index+1, index+2...\n- Quadratic probing: check index+1², index+2²...\n- Double hashing: use second hash function\n\n**Load factor** = n/capacity\n- Resize when load factor exceeds threshold (typically 0.75)",
    "example": "// Simple hash table with chaining\nclass HashTable {\n    private LinkedList<Entry>[] buckets;\n    private int size = 16;\n    \n    public void put(String key, int value) {\n        int index = hash(key) % size;\n        // Add to linked list at index (chaining)\n        buckets[index].add(new Entry(key, value));\n    }\n    \n    public int get(String key) {\n        int index = hash(key) % size;\n        // Search linked list for key\n        for (Entry e : buckets[index]) {\n            if (e.key.equals(key)) return e.value;\n        }\n        return -1;\n    }\n    \n    private int hash(String key) {\n        int h = 0;\n        for (char c : key.toCharArray()) {\n            h = 31 * h + c;  // Common string hash\n        }\n        return Math.abs(h);\n    }\n}\n\n// Collision example:\n// hash(\"ab\") % 10 = 5\n// hash(\"ba\") % 10 = 5  // Same bucket!\n// With chaining: bucket[5] -> [\"ab\": 1] -> [\"ba\": 2]"
  },
  {
    "id": 4,
    "question": "What is a Binary Search Tree (BST) and what are its properties?",
    "answer": "**Binary Search Tree** is a binary tree where each node follows the BST property:\n- Left subtree contains only nodes with keys less than the node's key\n- Right subtree contains only nodes with keys greater than the node's key\n- Both subtrees are also BSTs\n\n**Operations (average case):**\n- Search: O(log n)\n- Insert: O(log n)\n- Delete: O(log n)\n\n**Worst case:** O(n) when tree becomes a linked list (unbalanced)\n\n**Traversals:**\n- **In-order**: Left, Root, Right → Sorted order\n- **Pre-order**: Root, Left, Right → Copy tree\n- **Post-order**: Left, Right, Root → Delete tree\n\n**Balanced BSTs** (AVL, Red-Black) maintain O(log n) height",
    "example": "class TreeNode {\n    int val;\n    TreeNode left, right;\n}\n\n// Search in BST - O(log n) average\nTreeNode search(TreeNode root, int target) {\n    if (root == null || root.val == target) return root;\n    if (target < root.val) return search(root.left, target);\n    return search(root.right, target);\n}\n\n// Insert into BST\nTreeNode insert(TreeNode root, int val) {\n    if (root == null) return new TreeNode(val);\n    if (val < root.val) root.left = insert(root.left, val);\n    else root.right = insert(root.right, val);\n    return root;\n}\n\n// In-order traversal - prints sorted\nvoid inOrder(TreeNode root) {\n    if (root == null) return;\n    inOrder(root.left);\n    System.out.print(root.val + \" \");\n    inOrder(root.right);\n}\n\n// Example BST:\n//       8\n//      / \\\n//     3   10\n//    / \\    \\\n//   1   6    14\n// In-order: 1, 3, 6, 8, 10, 14 (sorted!)"
  },
  {
    "id": 5,
    "question": "Explain the difference between BFS and DFS traversal.",
    "answer": "**BFS (Breadth-First Search):**\n- Explores level by level\n- Uses a **Queue** (FIFO)\n- Finds shortest path in unweighted graphs\n- More memory for wide graphs\n- Good for: shortest path, level-order traversal\n\n**DFS (Depth-First Search):**\n- Explores as deep as possible first\n- Uses a **Stack** (or recursion)\n- May not find shortest path\n- Less memory for deep graphs\n- Good for: cycle detection, topological sort, pathfinding\n\n**Time Complexity:** Both O(V + E) for graphs\n\n**Space Complexity:**\n- BFS: O(width of graph/tree)\n- DFS: O(height of graph/tree)",
    "example": "// BFS using Queue\nvoid bfs(Node start) {\n    Queue<Node> queue = new LinkedList<>();\n    Set<Node> visited = new HashSet<>();\n    queue.offer(start);\n    visited.add(start);\n    \n    while (!queue.isEmpty()) {\n        Node node = queue.poll();\n        System.out.print(node.val + \" \");\n        for (Node neighbor : node.neighbors) {\n            if (!visited.contains(neighbor)) {\n                visited.add(neighbor);\n                queue.offer(neighbor);\n            }\n        }\n    }\n}\n\n// DFS using recursion (implicit stack)\nvoid dfs(Node node, Set<Node> visited) {\n    if (node == null || visited.contains(node)) return;\n    visited.add(node);\n    System.out.print(node.val + \" \");\n    for (Node neighbor : node.neighbors) {\n        dfs(neighbor, visited);\n    }\n}\n\n// Tree example:\n//       1\n//      / \\\n//     2   3\n//    / \\\n//   4   5\n// BFS: 1, 2, 3, 4, 5 (level by level)\n// DFS: 1, 2, 4, 5, 3 (deep first)"
  },
  {
    "id": 6,
    "question": "What is Dynamic Programming and when should you use it?",
    "answer": "**Dynamic Programming (DP)** is an optimization technique that solves complex problems by breaking them into overlapping subproblems and storing results to avoid recomputation.\n\n**Two key properties:**\n1. **Optimal Substructure**: Optimal solution contains optimal solutions to subproblems\n2. **Overlapping Subproblems**: Same subproblems are solved multiple times\n\n**Two approaches:**\n\n**Top-Down (Memoization):**\n- Start from original problem, recurse down\n- Cache results as you go\n- More intuitive, follows recursion\n\n**Bottom-Up (Tabulation):**\n- Start from smallest subproblems\n- Build up to original problem\n- Usually more space efficient\n\n**Common DP problems:**\nFibonacci, Coin Change, Longest Common Subsequence, Knapsack, Edit Distance",
    "example": "// Fibonacci - Classic DP example\n\n// Naive recursion - O(2^n) TIME!\nint fibNaive(int n) {\n    if (n <= 1) return n;\n    return fibNaive(n-1) + fibNaive(n-2);\n}\n\n// Top-Down with Memoization - O(n)\nint fibMemo(int n, int[] memo) {\n    if (n <= 1) return n;\n    if (memo[n] != 0) return memo[n];  // Return cached\n    memo[n] = fibMemo(n-1, memo) + fibMemo(n-2, memo);\n    return memo[n];\n}\n\n// Bottom-Up Tabulation - O(n) time, O(n) space\nint fibTab(int n) {\n    if (n <= 1) return n;\n    int[] dp = new int[n + 1];\n    dp[0] = 0; dp[1] = 1;\n    for (int i = 2; i <= n; i++) {\n        dp[i] = dp[i-1] + dp[i-2];\n    }\n    return dp[n];\n}\n\n// Space Optimized - O(n) time, O(1) space\nint fibOptimized(int n) {\n    if (n <= 1) return n;\n    int prev2 = 0, prev1 = 1;\n    for (int i = 2; i <= n; i++) {\n        int curr = prev1 + prev2;\n        prev2 = prev1;\n        prev1 = curr;\n    }\n    return prev1;\n}"
  },
  {
    "id": 7,
    "question": "How does Quick Sort work and what is its time complexity?",
    "answer": "**Quick Sort** is a divide-and-conquer sorting algorithm that selects a 'pivot' and partitions the array around it.\n\n**Algorithm:**\n1. Choose a pivot element\n2. Partition: move smaller elements left, larger elements right\n3. Recursively sort left and right partitions\n\n**Time Complexity:**\n- Best/Average: O(n log n)\n- Worst: O(n²) - when pivot is always min/max (sorted array with bad pivot)\n\n**Space Complexity:** O(log n) for recursion stack\n\n**Pivot selection strategies:**\n- First/Last element (simple but can be O(n²) on sorted input)\n- Random element (good average case)\n- Median-of-three (first, middle, last)\n\n**Advantages:** In-place, cache-friendly, fast in practice\n**Disadvantages:** Not stable, worst case O(n²)",
    "example": "void quickSort(int[] arr, int low, int high) {\n    if (low < high) {\n        int pivotIndex = partition(arr, low, high);\n        quickSort(arr, low, pivotIndex - 1);\n        quickSort(arr, pivotIndex + 1, high);\n    }\n}\n\nint partition(int[] arr, int low, int high) {\n    int pivot = arr[high];  // Choose last element as pivot\n    int i = low - 1;  // Index of smaller element\n    \n    for (int j = low; j < high; j++) {\n        if (arr[j] < pivot) {\n            i++;\n            swap(arr, i, j);\n        }\n    }\n    swap(arr, i + 1, high);  // Place pivot in correct position\n    return i + 1;\n}\n\n// Example: [3, 6, 2, 7, 1] with pivot = 1\n// After partition: [1, 6, 2, 7, 3] - 1 is in correct position\n// Left partition: [] (empty)\n// Right partition: [6, 2, 7, 3]\n// Continue recursively...\n\n// Randomized pivot (better average case):\n// int randomIndex = low + rand.nextInt(high - low + 1);\n// swap(arr, randomIndex, high);  // Move random to end\n// Then partition as usual"
  },
  {
    "id": 8,
    "question": "How does Merge Sort work and when is it preferred over Quick Sort?",
    "answer": "**Merge Sort** is a divide-and-conquer algorithm that divides the array in half, sorts each half, and merges them.\n\n**Algorithm:**\n1. Divide array into two halves\n2. Recursively sort each half\n3. Merge the two sorted halves\n\n**Time Complexity:** O(n log n) - always (best, average, worst)\n\n**Space Complexity:** O(n) for the merge step\n\n**When to prefer Merge Sort:**\n- Need guaranteed O(n log n)\n- Stability matters (preserves order of equal elements)\n- Sorting linked lists (no random access needed)\n- External sorting (large data on disk)\n\n**When to prefer Quick Sort:**\n- Average case performance matters more\n- Memory is constrained (in-place)\n- Cache performance is important",
    "example": "void mergeSort(int[] arr, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n        mergeSort(arr, left, mid);      // Sort left half\n        mergeSort(arr, mid + 1, right); // Sort right half\n        merge(arr, left, mid, right);   // Merge sorted halves\n    }\n}\n\nvoid merge(int[] arr, int left, int mid, int right) {\n    int[] temp = new int[right - left + 1];\n    int i = left, j = mid + 1, k = 0;\n    \n    // Compare and merge\n    while (i <= mid && j <= right) {\n        if (arr[i] <= arr[j]) {\n            temp[k++] = arr[i++];\n        } else {\n            temp[k++] = arr[j++];\n        }\n    }\n    \n    // Copy remaining elements\n    while (i <= mid) temp[k++] = arr[i++];\n    while (j <= right) temp[k++] = arr[j++];\n    \n    // Copy back to original array\n    System.arraycopy(temp, 0, arr, left, temp.length);\n}\n\n// Example: [38, 27, 43, 3]\n// Split: [38, 27] [43, 3]\n// Split: [38] [27] [43] [3]\n// Merge: [27, 38] [3, 43]\n// Merge: [3, 27, 38, 43]"
  },
  {
    "id": 9,
    "question": "What is a Heap and how is it used for priority queues?",
    "answer": "**Heap** is a complete binary tree that satisfies the heap property:\n\n**Max-Heap:** Parent ≥ children (root is maximum)\n**Min-Heap:** Parent ≤ children (root is minimum)\n\n**Key operations:**\n- Insert: O(log n) - add at end, bubble up\n- Extract min/max: O(log n) - remove root, bubble down\n- Peek: O(1) - return root without removing\n- Heapify: O(n) - build heap from array\n\n**Array representation:**\n- Parent of i: (i-1)/2\n- Left child of i: 2i+1\n- Right child of i: 2i+2\n\n**Priority Queue** is an abstract data type often implemented with a heap:\n- Elements have priorities\n- Highest (or lowest) priority served first\n- Used in: Dijkstra's algorithm, task scheduling, median finding",
    "example": "// Min-Heap implementation\nclass MinHeap {\n    private int[] heap;\n    private int size;\n    \n    void insert(int val) {\n        heap[size] = val;\n        bubbleUp(size);\n        size++;\n    }\n    \n    void bubbleUp(int i) {\n        while (i > 0 && heap[i] < heap[parent(i)]) {\n            swap(i, parent(i));\n            i = parent(i);\n        }\n    }\n    \n    int extractMin() {\n        int min = heap[0];\n        heap[0] = heap[--size];\n        bubbleDown(0);\n        return min;\n    }\n    \n    void bubbleDown(int i) {\n        int smallest = i;\n        int left = 2*i + 1, right = 2*i + 2;\n        if (left < size && heap[left] < heap[smallest])\n            smallest = left;\n        if (right < size && heap[right] < heap[smallest])\n            smallest = right;\n        if (smallest != i) {\n            swap(i, smallest);\n            bubbleDown(smallest);\n        }\n    }\n}\n\n// Java PriorityQueue (min-heap by default)\nPriorityQueue<Integer> pq = new PriorityQueue<>();\npq.offer(5); pq.offer(2); pq.offer(8);\npq.poll();  // Returns 2 (minimum)"
  },
  {
    "id": 10,
    "question": "What is a Graph and how can it be represented?",
    "answer": "**Graph** is a data structure consisting of vertices (nodes) and edges connecting them.\n\n**Types:**\n- **Directed vs Undirected**: Edges have direction or not\n- **Weighted vs Unweighted**: Edges have values or not\n- **Cyclic vs Acyclic**: Contains cycles or not\n- **Connected vs Disconnected**: All vertices reachable or not\n\n**Representations:**\n\n**Adjacency Matrix:**\n- 2D array where matrix[i][j] = 1 if edge exists\n- Space: O(V²)\n- Check edge: O(1)\n- Find neighbors: O(V)\n- Good for dense graphs\n\n**Adjacency List:**\n- Array of lists, each list contains neighbors\n- Space: O(V + E)\n- Check edge: O(degree)\n- Find neighbors: O(1)\n- Good for sparse graphs (most real-world graphs)",
    "example": "// Adjacency List representation\nclass Graph {\n    private List<List<Integer>> adjList;\n    private int vertices;\n    \n    Graph(int v) {\n        vertices = v;\n        adjList = new ArrayList<>();\n        for (int i = 0; i < v; i++) {\n            adjList.add(new ArrayList<>());\n        }\n    }\n    \n    void addEdge(int src, int dest) {\n        adjList.get(src).add(dest);\n        adjList.get(dest).add(src);  // Remove for directed\n    }\n    \n    List<Integer> getNeighbors(int v) {\n        return adjList.get(v);\n    }\n}\n\n// Adjacency Matrix representation\nint[][] matrix = new int[V][V];\nvoid addEdge(int src, int dest) {\n    matrix[src][dest] = 1;\n    matrix[dest][src] = 1;  // Remove for directed\n}\n\n// Example Graph:\n// 0 -- 1\n// |    |\n// 3 -- 2\n// Adjacency List:\n// 0: [1, 3]\n// 1: [0, 2]\n// 2: [1, 3]\n// 3: [0, 2]\n// Adjacency Matrix:\n//   0 1 2 3\n// 0 [0 1 0 1]\n// 1 [1 0 1 0]\n// 2 [0 1 0 1]\n// 3 [1 0 1 0]"
  },
  {
    "id": 11,
    "question": "What is a Stack and what are its common applications?",
    "answer": "**Stack** is a LIFO (Last-In-First-Out) data structure.\n\n**Operations (all O(1)):**\n- **push**: Add element to top\n- **pop**: Remove and return top element\n- **peek/top**: Return top element without removing\n- **isEmpty**: Check if stack is empty\n\n**Common applications:**\n- Function call stack (recursion)\n- Undo/Redo operations\n- Browser back button\n- Expression evaluation (postfix, infix)\n- Parentheses matching\n- DFS traversal\n- Backtracking algorithms\n\n**Implementation:**\n- Array-based: Fixed size, but cache-friendly\n- Linked list-based: Dynamic size",
    "example": "// Stack implementation using array\nclass Stack {\n    private int[] arr;\n    private int top = -1;\n    \n    void push(int val) {\n        arr[++top] = val;\n    }\n    \n    int pop() {\n        return arr[top--];\n    }\n    \n    int peek() {\n        return arr[top];\n    }\n}\n\n// Valid Parentheses - Classic stack problem\nboolean isValid(String s) {\n    Stack<Character> stack = new Stack<>();\n    for (char c : s.toCharArray()) {\n        if (c == '(' || c == '[' || c == '{') {\n            stack.push(c);\n        } else {\n            if (stack.isEmpty()) return false;\n            char open = stack.pop();\n            if ((c == ')' && open != '(') ||\n                (c == ']' && open != '[') ||\n                (c == '}' && open != '{')) {\n                return false;\n            }\n        }\n    }\n    return stack.isEmpty();\n}\n\n// isValid(\"({[]})\"): true\n// isValid(\"([)]\"): false"
  },
  {
    "id": 12,
    "question": "What is a Queue and what are its variants?",
    "answer": "**Queue** is a FIFO (First-In-First-Out) data structure.\n\n**Operations (all O(1)):**\n- **enqueue/offer**: Add element to back\n- **dequeue/poll**: Remove and return front element\n- **peek/front**: Return front element without removing\n- **isEmpty**: Check if queue is empty\n\n**Variants:**\n\n**Circular Queue:**\n- Array wraps around to reuse space\n- Efficient fixed-size queue\n\n**Double-ended Queue (Deque):**\n- Insert/remove from both ends\n- Can function as stack or queue\n\n**Priority Queue:**\n- Elements served by priority, not order\n- Usually implemented with heap\n\n**Applications:**\n- BFS traversal, task scheduling, buffering, printer queue",
    "example": "// Circular Queue implementation\nclass CircularQueue {\n    private int[] arr;\n    private int front = 0, rear = -1, size = 0;\n    private int capacity;\n    \n    void enqueue(int val) {\n        rear = (rear + 1) % capacity;\n        arr[rear] = val;\n        size++;\n    }\n    \n    int dequeue() {\n        int val = arr[front];\n        front = (front + 1) % capacity;\n        size--;\n        return val;\n    }\n}\n\n// Deque usage - sliding window maximum\nint[] maxSlidingWindow(int[] nums, int k) {\n    Deque<Integer> deque = new ArrayDeque<>();\n    int[] result = new int[nums.length - k + 1];\n    \n    for (int i = 0; i < nums.length; i++) {\n        // Remove indices outside window\n        while (!deque.isEmpty() && deque.peekFirst() < i - k + 1) {\n            deque.pollFirst();\n        }\n        // Remove smaller elements (useless)\n        while (!deque.isEmpty() && nums[deque.peekLast()] < nums[i]) {\n            deque.pollLast();\n        }\n        deque.offerLast(i);\n        \n        if (i >= k - 1) {\n            result[i - k + 1] = nums[deque.peekFirst()];\n        }\n    }\n    return result;\n}"
  },
  {
    "id": 13,
    "question": "What is the Two Pointer technique?",
    "answer": "**Two Pointer** is a technique using two indices to traverse data structures, typically arrays or linked lists.\n\n**Common patterns:**\n\n**1. Opposite ends (converging):**\n- Start from both ends, move toward middle\n- Used for: sorted array problems, palindrome check\n\n**2. Same direction (fast/slow):**\n- Both start from beginning, move at different speeds\n- Used for: cycle detection, finding middle, removing duplicates\n\n**3. Sliding window:**\n- Both pointers define a window range\n- Used for: subarray problems, string matching\n\n**Time Complexity:** Usually O(n) - single pass\n**Space Complexity:** O(1) - no extra space needed\n\n**Key insight:** Reduces O(n²) brute force to O(n)",
    "example": "// Pattern 1: Two Sum in sorted array (opposite ends)\nint[] twoSum(int[] nums, int target) {\n    int left = 0, right = nums.length - 1;\n    while (left < right) {\n        int sum = nums[left] + nums[right];\n        if (sum == target) return new int[]{left, right};\n        if (sum < target) left++;\n        else right--;\n    }\n    return new int[]{-1, -1};\n}\n\n// Pattern 2: Linked List cycle detection (fast/slow)\nboolean hasCycle(ListNode head) {\n    ListNode slow = head, fast = head;\n    while (fast != null && fast.next != null) {\n        slow = slow.next;\n        fast = fast.next.next;\n        if (slow == fast) return true;\n    }\n    return false;\n}\n\n// Pattern 3: Remove duplicates in-place\nint removeDuplicates(int[] nums) {\n    if (nums.length == 0) return 0;\n    int slow = 0;\n    for (int fast = 1; fast < nums.length; fast++) {\n        if (nums[fast] != nums[slow]) {\n            slow++;\n            nums[slow] = nums[fast];\n        }\n    }\n    return slow + 1;\n}\n// [1,1,2,3,3] -> [1,2,3,_,_], returns 3"
  },
  {
    "id": 14,
    "question": "What is the Sliding Window technique?",
    "answer": "**Sliding Window** is a technique for problems involving contiguous sequences (subarrays, substrings) that optimizes brute force O(n²) to O(n).\n\n**Types:**\n\n**Fixed-size window:**\n- Window size is given\n- Slide window one element at a time\n- Add new element, remove old element\n\n**Variable-size window:**\n- Expand window to meet condition\n- Shrink window to optimize\n- Track best result\n\n**Common problems:**\n- Maximum sum subarray of size k\n- Longest substring without repeating characters\n- Minimum window substring\n- Maximum of all subarrays of size k\n\n**Key insight:** Reuse computation from previous window instead of recalculating",
    "example": "// Fixed window: Max sum of subarray size k\nint maxSumSubarray(int[] arr, int k) {\n    int windowSum = 0, maxSum = 0;\n    \n    // Build first window\n    for (int i = 0; i < k; i++) {\n        windowSum += arr[i];\n    }\n    maxSum = windowSum;\n    \n    // Slide window\n    for (int i = k; i < arr.length; i++) {\n        windowSum += arr[i] - arr[i - k];  // Add new, remove old\n        maxSum = Math.max(maxSum, windowSum);\n    }\n    return maxSum;\n}\n\n// Variable window: Longest substring without repeating\nint lengthOfLongestSubstring(String s) {\n    Set<Character> set = new HashSet<>();\n    int left = 0, maxLen = 0;\n    \n    for (int right = 0; right < s.length(); right++) {\n        // Shrink window until no duplicate\n        while (set.contains(s.charAt(right))) {\n            set.remove(s.charAt(left));\n            left++;\n        }\n        set.add(s.charAt(right));\n        maxLen = Math.max(maxLen, right - left + 1);\n    }\n    return maxLen;\n}\n// \"abcabcbb\" -> 3 (\"abc\")"
  },
  {
    "id": 15,
    "question": "What is Binary Search and when can it be applied?",
    "answer": "**Binary Search** is a divide-and-conquer algorithm that finds a target in a sorted array by repeatedly halving the search space.\n\n**Requirements:**\n- Sorted array (or monotonic condition)\n- Random access (arrays, not linked lists)\n\n**Time Complexity:** O(log n)\n**Space Complexity:** O(1) iterative, O(log n) recursive\n\n**Applications beyond simple search:**\n- Finding first/last occurrence\n- Search in rotated sorted array\n- Finding square root\n- Search insert position\n- Peak finding\n- Minimizing/maximizing with monotonic check function\n\n**Common mistakes:**\n- Integer overflow: use `mid = left + (right - left) / 2`\n- Off-by-one errors in boundary conditions\n- Infinite loops with wrong pointer updates",
    "example": "// Standard binary search\nint binarySearch(int[] arr, int target) {\n    int left = 0, right = arr.length - 1;\n    while (left <= right) {\n        int mid = left + (right - left) / 2;  // Avoid overflow\n        if (arr[mid] == target) return mid;\n        if (arr[mid] < target) left = mid + 1;\n        else right = mid - 1;\n    }\n    return -1;  // Not found\n}\n\n// Find first occurrence (leftmost)\nint findFirst(int[] arr, int target) {\n    int left = 0, right = arr.length - 1;\n    int result = -1;\n    while (left <= right) {\n        int mid = left + (right - left) / 2;\n        if (arr[mid] == target) {\n            result = mid;\n            right = mid - 1;  // Keep searching left\n        } else if (arr[mid] < target) {\n            left = mid + 1;\n        } else {\n            right = mid - 1;\n        }\n    }\n    return result;\n}\n\n// Binary search on answer space\n// Find square root of n (integer)\nint sqrt(int n) {\n    int left = 0, right = n, result = 0;\n    while (left <= right) {\n        int mid = left + (right - left) / 2;\n        if ((long)mid * mid <= n) {\n            result = mid;\n            left = mid + 1;\n        } else {\n            right = mid - 1;\n        }\n    }\n    return result;\n}"
  },
  {
    "id": 16,
    "question": "What is a Trie and when is it useful?",
    "answer": "**Trie** (prefix tree) is a tree-like data structure for storing strings where each node represents a character.\n\n**Properties:**\n- Root is empty\n- Each path from root represents a prefix\n- Nodes may have flag indicating complete word\n- Children indexed by character\n\n**Operations:**\n- Insert: O(m) where m is word length\n- Search: O(m)\n- Prefix search: O(m)\n\n**Space:** O(alphabet_size × m × n) for n words\n\n**Use cases:**\n- Autocomplete/typeahead\n- Spell checker\n- IP routing (longest prefix match)\n- Word games (Boggle, Scrabble)\n- Searching for words with common prefix\n\n**Advantages over hash table:**\n- Prefix operations are natural\n- No hash collisions\n- Alphabetically ordered iteration",
    "example": "class TrieNode {\n    TrieNode[] children = new TrieNode[26];\n    boolean isEndOfWord = false;\n}\n\nclass Trie {\n    private TrieNode root = new TrieNode();\n    \n    void insert(String word) {\n        TrieNode node = root;\n        for (char c : word.toCharArray()) {\n            int index = c - 'a';\n            if (node.children[index] == null) {\n                node.children[index] = new TrieNode();\n            }\n            node = node.children[index];\n        }\n        node.isEndOfWord = true;\n    }\n    \n    boolean search(String word) {\n        TrieNode node = findNode(word);\n        return node != null && node.isEndOfWord;\n    }\n    \n    boolean startsWith(String prefix) {\n        return findNode(prefix) != null;\n    }\n    \n    private TrieNode findNode(String s) {\n        TrieNode node = root;\n        for (char c : s.toCharArray()) {\n            int index = c - 'a';\n            if (node.children[index] == null) return null;\n            node = node.children[index];\n        }\n        return node;\n    }\n}\n\n// Visual: insert \"cat\", \"car\", \"card\"\n//        root\n//         |\n//         c\n//         |\n//         a\n//        / \\\n//       t   r*\n//       *   |\n//           d*\n// * = isEndOfWord"
  },
  {
    "id": 17,
    "question": "What is Dijkstra's algorithm?",
    "answer": "**Dijkstra's algorithm** finds the shortest path from a source vertex to all other vertices in a weighted graph with non-negative edge weights.\n\n**Algorithm:**\n1. Initialize distances: source = 0, others = ∞\n2. Use priority queue (min-heap) ordered by distance\n3. Extract minimum distance vertex\n4. Update distances to neighbors if shorter path found\n5. Repeat until queue is empty\n\n**Time Complexity:**\n- With binary heap: O((V + E) log V)\n- With Fibonacci heap: O(E + V log V)\n\n**Space Complexity:** O(V)\n\n**Limitations:**\n- Doesn't work with negative edge weights\n- Use Bellman-Ford for negative weights\n\n**Applications:**\n- GPS navigation, network routing, game AI pathfinding",
    "example": "int[] dijkstra(int[][] graph, int src, int V) {\n    int[] dist = new int[V];\n    Arrays.fill(dist, Integer.MAX_VALUE);\n    dist[src] = 0;\n    \n    // Min-heap: {distance, vertex}\n    PriorityQueue<int[]> pq = new PriorityQueue<>(\n        (a, b) -> a[0] - b[0]\n    );\n    pq.offer(new int[]{0, src});\n    \n    while (!pq.isEmpty()) {\n        int[] curr = pq.poll();\n        int d = curr[0], u = curr[1];\n        \n        if (d > dist[u]) continue;  // Skip outdated entries\n        \n        // Check all neighbors\n        for (int v = 0; v < V; v++) {\n            if (graph[u][v] != 0) {  // Edge exists\n                int newDist = dist[u] + graph[u][v];\n                if (newDist < dist[v]) {\n                    dist[v] = newDist;\n                    pq.offer(new int[]{newDist, v});\n                }\n            }\n        }\n    }\n    return dist;\n}\n\n// Example graph:\n//     1 ---(4)--- 2\n//     |          /|\n//    (1)      (2) (1)\n//     |      /    |\n//     0 --(2)---- 3\n// From 0: dist = [0, 1, 3, 2]"
  },
  {
    "id": 18,
    "question": "What is the difference between recursive and iterative solutions?",
    "answer": "**Recursive solution:**\n- Function calls itself with smaller subproblem\n- Uses call stack implicitly\n- Often more intuitive and elegant\n- Risk of stack overflow for deep recursion\n- Space: O(depth) for call stack\n\n**Iterative solution:**\n- Uses explicit loops\n- May use explicit stack/queue\n- Usually more efficient (no function call overhead)\n- No stack overflow risk\n- Space: Often O(1) or explicit data structure\n\n**Converting recursion to iteration:**\n- Simple cases: Tail recursion can become a loop\n- Complex cases: Use explicit stack to simulate call stack\n\n**When to use each:**\n- Recursive: Tree traversals, divide-and-conquer, when logic is cleaner\n- Iterative: Performance critical, limited stack space, simple loops",
    "example": "// Factorial - simple recursion to iteration\n\n// Recursive - O(n) space for call stack\nint factorialRec(int n) {\n    if (n <= 1) return 1;\n    return n * factorialRec(n - 1);\n}\n\n// Iterative - O(1) space\nint factorialIter(int n) {\n    int result = 1;\n    for (int i = 2; i <= n; i++) {\n        result *= i;\n    }\n    return result;\n}\n\n// Tree traversal - complex recursion to iteration\n\n// Recursive inorder\nvoid inorderRec(TreeNode root) {\n    if (root == null) return;\n    inorderRec(root.left);\n    visit(root);\n    inorderRec(root.right);\n}\n\n// Iterative inorder with explicit stack\nvoid inorderIter(TreeNode root) {\n    Stack<TreeNode> stack = new Stack<>();\n    TreeNode curr = root;\n    while (curr != null || !stack.isEmpty()) {\n        while (curr != null) {\n            stack.push(curr);\n            curr = curr.left;\n        }\n        curr = stack.pop();\n        visit(curr);\n        curr = curr.right;\n    }\n}"
  },
  {
    "id": 19,
    "question": "What is Topological Sort and when is it used?",
    "answer": "**Topological Sort** is a linear ordering of vertices in a Directed Acyclic Graph (DAG) such that for every edge (u, v), u comes before v.\n\n**Properties:**\n- Only works on DAGs (no cycles)\n- Multiple valid orderings may exist\n- Used to find a valid sequence respecting dependencies\n\n**Algorithms:**\n\n**Kahn's Algorithm (BFS-based):**\n- Track in-degree of each vertex\n- Start with in-degree 0 vertices\n- Remove vertex, decrease neighbors' in-degree\n- Repeat until done\n\n**DFS-based:**\n- Do DFS, add vertex to result after all descendants visited\n- Reverse result for topological order\n\n**Time Complexity:** O(V + E)\n\n**Applications:**\n- Build systems (makefile), task scheduling, course prerequisites, dependency resolution",
    "example": "// Kahn's Algorithm (BFS)\nList<Integer> topologicalSort(int V, List<List<Integer>> adj) {\n    int[] inDegree = new int[V];\n    \n    // Calculate in-degrees\n    for (int u = 0; u < V; u++) {\n        for (int v : adj.get(u)) {\n            inDegree[v]++;\n        }\n    }\n    \n    Queue<Integer> queue = new LinkedList<>();\n    for (int i = 0; i < V; i++) {\n        if (inDegree[i] == 0) queue.offer(i);\n    }\n    \n    List<Integer> result = new ArrayList<>();\n    while (!queue.isEmpty()) {\n        int u = queue.poll();\n        result.add(u);\n        \n        for (int v : adj.get(u)) {\n            inDegree[v]--;\n            if (inDegree[v] == 0) queue.offer(v);\n        }\n    }\n    \n    // If result size != V, cycle exists\n    return result.size() == V ? result : new ArrayList<>();\n}\n\n// Example: Course prerequisites\n// 0 -> 1 -> 2\n//      |    |\n//      v    v\n//      3 -> 4\n// Valid orderings: [0,1,2,3,4] or [0,1,3,2,4]"
  },
  {
    "id": 20,
    "question": "What is the Knapsack problem and its variants?",
    "answer": "**Knapsack Problem** is a classic optimization problem: given items with weights and values, maximize value while staying within weight capacity.\n\n**Variants:**\n\n**0/1 Knapsack:**\n- Each item can be taken once or not at all\n- DP solution: O(n × W) time and space\n\n**Unbounded Knapsack:**\n- Each item can be taken unlimited times\n- DP solution: O(n × W)\n\n**Fractional Knapsack:**\n- Can take fractions of items\n- Greedy solution: O(n log n)\n- Sort by value/weight ratio\n\n**Related problems:**\n- Subset Sum: Can subset sum to target?\n- Coin Change: Minimum coins for amount\n- Partition Equal Subset Sum",
    "example": "// 0/1 Knapsack\nint knapsack01(int[] weights, int[] values, int W) {\n    int n = weights.length;\n    int[][] dp = new int[n + 1][W + 1];\n    \n    for (int i = 1; i <= n; i++) {\n        for (int w = 0; w <= W; w++) {\n            // Don't take item i\n            dp[i][w] = dp[i-1][w];\n            // Take item i (if it fits)\n            if (weights[i-1] <= w) {\n                dp[i][w] = Math.max(\n                    dp[i][w],\n                    dp[i-1][w - weights[i-1]] + values[i-1]\n                );\n            }\n        }\n    }\n    return dp[n][W];\n}\n\n// Space optimized to O(W)\nint knapsack01Optimized(int[] weights, int[] values, int W) {\n    int[] dp = new int[W + 1];\n    for (int i = 0; i < weights.length; i++) {\n        for (int w = W; w >= weights[i]; w--) {  // Reverse!\n            dp[w] = Math.max(dp[w], dp[w - weights[i]] + values[i]);\n        }\n    }\n    return dp[W];\n}\n\n// Example: weights=[2,3,4], values=[3,4,5], W=5\n// Take items 0,1: weight=5, value=7\n// dp[5] = 7"
  }
]
