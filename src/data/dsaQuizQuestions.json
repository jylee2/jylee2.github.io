[
  {
    "id": 1,
    "question": "What is the difference between an Array and a Linked List?",
    "answer": "**Array:**\n- Contiguous memory allocation\n- Fixed size (in most languages) or dynamic with reallocation\n- O(1) random access by index\n- O(n) insertion/deletion in middle (shifting required)\n- Cache-friendly due to locality\n\n**Linked List:**\n- Non-contiguous memory (nodes with pointers)\n- Dynamic size, grows easily\n- O(n) access (must traverse)\n- O(1) insertion/deletion if you have the node reference\n- Extra memory for pointers\n\n**When to use:**\n- Array: Frequent access by index, known size, cache performance matters\n- Linked List: Frequent insertions/deletions, unknown size, no random access needed",
    "example": "// Array - O(1) access, O(n) insert at beginning\nlet arr = [1, 2, 3, 4, 5];\narr[2];           // O(1) - returns 3\narr.unshift(0);   // O(n) - shifts all elements\n\n// Linked List - O(n) access, O(1) insert at beginning\nclass Node {\n  constructor(val) {\n    this.val = val;\n    this.next = null;\n  }\n}\n\nclass LinkedList {\n  constructor() {\n    this.head = null;\n  }\n  \n  // O(1) insert at head\n  prepend(val) {\n    const node = new Node(val);\n    node.next = this.head;\n    this.head = node;\n  }\n  \n  // O(n) access by index\n  get(index) {\n    let current = this.head;\n    for (let i = 0; i < index && current; i++) {\n      current = current.next;\n    }\n    return current?.val;\n  }\n}"
  },
  {
    "id": 2,
    "question": "What is Big O notation and what are common time complexities?",
    "answer": "**Big O notation** describes the upper bound of an algorithm's time or space complexity as input size grows.\n\n**Common complexities (fastest to slowest):**\n\n- **O(1)** - Constant: Hash table lookup, array access\n- **O(log n)** - Logarithmic: Binary search, balanced BST operations\n- **O(n)** - Linear: Linear search, single loop\n- **O(n log n)** - Linearithmic: Merge sort, heap sort, efficient sorting\n- **O(n²)** - Quadratic: Nested loops, bubble sort, insertion sort\n- **O(2ⁿ)** - Exponential: Recursive fibonacci, subset generation\n- **O(n!)** - Factorial: Permutations, traveling salesman brute force\n\n**Rules:**\n- Drop constants: O(2n) → O(n)\n- Drop lower terms: O(n² + n) → O(n²)\n- Consider worst case unless specified",
    "example": "// O(1) - Constant\nfunction getFirst(arr) {\n  return arr[0];\n}\n\n// O(log n) - Logarithmic\nfunction binarySearch(arr, target) {\n  let left = 0, right = arr.length - 1;\n  while (left <= right) {\n    const mid = Math.floor((left + right) / 2);\n    if (arr[mid] === target) return mid;\n    if (arr[mid] < target) left = mid + 1;\n    else right = mid - 1;\n  }\n  return -1;\n}\n\n// O(n) - Linear\nfunction sum(arr) {\n  return arr.reduce((a, b) => a + b, 0);\n}\n\n// O(n²) - Quadratic\nfunction bubbleSort(arr) {\n  for (let i = 0; i < arr.length; i++) {\n    for (let j = 0; j < arr.length - 1; j++) {\n      if (arr[j] > arr[j + 1]) {\n        [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];\n      }\n    }\n  }\n}"
  },
  {
    "id": 3,
    "question": "What is a Hash Table and how does it handle collisions?",
    "answer": "A **Hash Table** (hash map) stores key-value pairs using a hash function to compute an index into an array of buckets.\n\n**Operations:** Average O(1) for insert, delete, lookup\n\n**Hash function**: Converts key → array index\n- Good hash: uniform distribution, deterministic, fast\n\n**Collision handling methods:**\n\n**1. Chaining (Separate Chaining)**\n- Each bucket contains a linked list\n- Collisions add to the list\n- Simple but uses extra memory\n\n**2. Open Addressing**\n- Find another empty slot in the array\n- Linear probing: check next slot\n- Quadratic probing: check i² slots away\n- Double hashing: use second hash function\n\n**Load factor** = n/k (items/buckets)\n- Resize when load factor exceeds threshold (typically 0.75)",
    "example": "// Simple hash table with chaining\nclass HashTable {\n  constructor(size = 53) {\n    this.buckets = new Array(size);\n    this.size = size;\n  }\n\n  _hash(key) {\n    let hash = 0;\n    for (let char of key) {\n      hash = (hash * 31 + char.charCodeAt(0)) % this.size;\n    }\n    return hash;\n  }\n\n  set(key, value) {\n    const index = this._hash(key);\n    if (!this.buckets[index]) {\n      this.buckets[index] = [];\n    }\n    // Check if key exists, update if so\n    const existing = this.buckets[index].find(([k]) => k === key);\n    if (existing) existing[1] = value;\n    else this.buckets[index].push([key, value]);\n  }\n\n  get(key) {\n    const index = this._hash(key);\n    const bucket = this.buckets[index];\n    if (!bucket) return undefined;\n    const pair = bucket.find(([k]) => k === key);\n    return pair ? pair[1] : undefined;\n  }\n}\n\nconst ht = new HashTable();\nht.set('name', 'Alice');  // O(1) average\nht.get('name');           // O(1) average → 'Alice'"
  },
  {
    "id": 4,
    "question": "What is a Binary Search Tree (BST) and what are its properties?",
    "answer": "A **Binary Search Tree** is a binary tree where each node follows the BST property:\n- Left subtree contains only nodes with keys less than the node's key\n- Right subtree contains only nodes with keys greater than the node's key\n- Both subtrees are also BSTs\n\n**Operations:**\n- Search: O(log n) average, O(n) worst (unbalanced)\n- Insert: O(log n) average, O(n) worst\n- Delete: O(log n) average, O(n) worst\n- In-order traversal: Gives sorted order\n\n**Balanced BSTs** maintain O(log n) height:\n- AVL Tree: Strict balance (height diff ≤ 1)\n- Red-Black Tree: Relaxed balance, faster insertions\n- B-Tree: Used in databases, multiple keys per node\n\n**Worst case**: Inserting sorted data creates a linked list (O(n) operations)",
    "example": "class TreeNode {\n  constructor(val) {\n    this.val = val;\n    this.left = null;\n    this.right = null;\n  }\n}\n\nclass BST {\n  constructor() {\n    this.root = null;\n  }\n\n  insert(val) {\n    const node = new TreeNode(val);\n    if (!this.root) {\n      this.root = node;\n      return;\n    }\n    let current = this.root;\n    while (true) {\n      if (val < current.val) {\n        if (!current.left) { current.left = node; return; }\n        current = current.left;\n      } else {\n        if (!current.right) { current.right = node; return; }\n        current = current.right;\n      }\n    }\n  }\n\n  search(val) {\n    let current = this.root;\n    while (current) {\n      if (val === current.val) return current;\n      current = val < current.val ? current.left : current.right;\n    }\n    return null;\n  }\n\n  // In-order: Left, Root, Right → Sorted order\n  inOrder(node = this.root, result = []) {\n    if (node) {\n      this.inOrder(node.left, result);\n      result.push(node.val);\n      this.inOrder(node.right, result);\n    }\n    return result;\n  }\n}"
  },
  {
    "id": 5,
    "question": "What is the difference between a Stack and a Queue?",
    "answer": "**Stack (LIFO - Last In, First Out)**\n- Think: stack of plates\n- Operations: push (top), pop (top), peek (top)\n- All operations O(1)\n- Use cases: function calls, undo/redo, expression evaluation, DFS\n\n**Queue (FIFO - First In, First Out)**\n- Think: line at a store\n- Operations: enqueue (back), dequeue (front), peek (front)\n- All operations O(1) with proper implementation\n- Use cases: BFS, task scheduling, buffers, print queue\n\n**Variants:**\n- **Deque**: Double-ended queue, insert/remove both ends\n- **Priority Queue**: Elements have priority, highest priority out first (heap-based)\n- **Circular Queue**: Fixed size, wraps around",
    "example": "// Stack implementation\nclass Stack {\n  constructor() {\n    this.items = [];\n  }\n  push(val) { this.items.push(val); }\n  pop() { return this.items.pop(); }\n  peek() { return this.items[this.items.length - 1]; }\n  isEmpty() { return this.items.length === 0; }\n}\n\n// Queue implementation (using array - dequeue is O(n))\n// For O(1) dequeue, use linked list or circular buffer\nclass Queue {\n  constructor() {\n    this.items = [];\n  }\n  enqueue(val) { this.items.push(val); }\n  dequeue() { return this.items.shift(); } // O(n) with array\n  peek() { return this.items[0]; }\n  isEmpty() { return this.items.length === 0; }\n}\n\n// Usage - Stack for DFS, Queue for BFS\nconst stack = new Stack();\nstack.push(1); stack.push(2); stack.push(3);\nstack.pop(); // 3 (last in, first out)\n\nconst queue = new Queue();\nqueue.enqueue(1); queue.enqueue(2); queue.enqueue(3);\nqueue.dequeue(); // 1 (first in, first out)"
  },
  {
    "id": 6,
    "question": "Explain Depth-First Search (DFS) and Breadth-First Search (BFS).",
    "answer": "**DFS (Depth-First Search)**\n- Explores as deep as possible before backtracking\n- Uses: Stack (or recursion)\n- Time: O(V + E) for graphs, O(n) for trees\n- Space: O(h) where h is height (recursion stack)\n- Use cases: Path finding, cycle detection, topological sort, maze solving\n\n**BFS (Breadth-First Search)**\n- Explores all neighbors at current depth before going deeper\n- Uses: Queue\n- Time: O(V + E) for graphs, O(n) for trees\n- Space: O(w) where w is max width\n- Use cases: Shortest path (unweighted), level-order traversal, nearest neighbor\n\n**Key difference**: DFS goes deep first, BFS goes wide first.\n\n**Shortest path**: BFS finds shortest path in unweighted graphs; DFS does not guarantee shortest path.",
    "example": "// DFS - Using recursion (implicit stack)\nfunction dfs(node, visited = new Set()) {\n  if (!node || visited.has(node)) return;\n  console.log(node.val);\n  visited.add(node);\n  for (const neighbor of node.neighbors) {\n    dfs(neighbor, visited);\n  }\n}\n\n// DFS - Using explicit stack\nfunction dfsIterative(root) {\n  const stack = [root];\n  const visited = new Set();\n  while (stack.length) {\n    const node = stack.pop();\n    if (visited.has(node)) continue;\n    visited.add(node);\n    console.log(node.val);\n    for (const neighbor of node.neighbors) {\n      stack.push(neighbor);\n    }\n  }\n}\n\n// BFS - Using queue\nfunction bfs(root) {\n  const queue = [root];\n  const visited = new Set([root]);\n  while (queue.length) {\n    const node = queue.shift();\n    console.log(node.val);\n    for (const neighbor of node.neighbors) {\n      if (!visited.has(neighbor)) {\n        visited.add(neighbor);\n        queue.push(neighbor);\n      }\n    }\n  }\n}"
  },
  {
    "id": 7,
    "question": "What is Dynamic Programming and when should you use it?",
    "answer": "**Dynamic Programming (DP)** is an optimization technique that solves complex problems by breaking them into overlapping subproblems and storing their solutions.\n\n**Two key properties for DP:**\n1. **Optimal substructure**: Optimal solution contains optimal solutions to subproblems\n2. **Overlapping subproblems**: Same subproblems are solved multiple times\n\n**Approaches:**\n- **Top-down (Memoization)**: Recursion + cache results\n- **Bottom-up (Tabulation)**: Build solution iteratively from base cases\n\n**Common patterns:**\n- Fibonacci-style: Current depends on previous values\n- Grid traversal: Paths, min cost\n- String problems: LCS, edit distance\n- Knapsack: Subset selection with constraints\n\n**Steps to solve:**\n1. Define state (what changes between subproblems)\n2. Find recurrence relation\n3. Identify base cases\n4. Decide iteration order or use memoization",
    "example": "// Fibonacci - Shows DP transformation\n\n// Naive recursion - O(2^n) - overlapping subproblems!\nfunction fibNaive(n) {\n  if (n <= 1) return n;\n  return fibNaive(n - 1) + fibNaive(n - 2);\n}\n\n// Top-down with memoization - O(n)\nfunction fibMemo(n, memo = {}) {\n  if (n in memo) return memo[n];\n  if (n <= 1) return n;\n  memo[n] = fibMemo(n - 1, memo) + fibMemo(n - 2, memo);\n  return memo[n];\n}\n\n// Bottom-up tabulation - O(n) time, O(n) space\nfunction fibTab(n) {\n  if (n <= 1) return n;\n  const dp = [0, 1];\n  for (let i = 2; i <= n; i++) {\n    dp[i] = dp[i - 1] + dp[i - 2];\n  }\n  return dp[n];\n}\n\n// Bottom-up optimized - O(n) time, O(1) space\nfunction fibOptimized(n) {\n  if (n <= 1) return n;\n  let prev2 = 0, prev1 = 1;\n  for (let i = 2; i <= n; i++) {\n    const curr = prev1 + prev2;\n    prev2 = prev1;\n    prev1 = curr;\n  }\n  return prev1;\n}"
  },
  {
    "id": 8,
    "question": "What is a Heap and how is it used for a Priority Queue?",
    "answer": "A **Heap** is a complete binary tree satisfying the heap property:\n- **Max-Heap**: Parent ≥ children (max at root)\n- **Min-Heap**: Parent ≤ children (min at root)\n\n**Properties:**\n- Complete binary tree (filled level by level)\n- Efficiently stored in array: parent at i, children at 2i+1, 2i+2\n- Height: O(log n)\n\n**Operations:**\n- **Insert**: Add at end, bubble up - O(log n)\n- **Extract max/min**: Remove root, replace with last, bubble down - O(log n)\n- **Peek**: O(1)\n- **Heapify array**: O(n)\n\n**Priority Queue**: Abstract data type where elements have priorities\n- Implemented efficiently with a heap\n- Use cases: Dijkstra's algorithm, task scheduling, median finding, K largest/smallest",
    "example": "class MinHeap {\n  constructor() {\n    this.heap = [];\n  }\n\n  parent(i) { return Math.floor((i - 1) / 2); }\n  leftChild(i) { return 2 * i + 1; }\n  rightChild(i) { return 2 * i + 2; }\n\n  swap(i, j) {\n    [this.heap[i], this.heap[j]] = [this.heap[j], this.heap[i]];\n  }\n\n  insert(val) {\n    this.heap.push(val);\n    this.bubbleUp(this.heap.length - 1);\n  }\n\n  bubbleUp(i) {\n    while (i > 0 && this.heap[i] < this.heap[this.parent(i)]) {\n      this.swap(i, this.parent(i));\n      i = this.parent(i);\n    }\n  }\n\n  extractMin() {\n    if (this.heap.length === 0) return null;\n    const min = this.heap[0];\n    this.heap[0] = this.heap.pop();\n    this.bubbleDown(0);\n    return min;\n  }\n\n  bubbleDown(i) {\n    const n = this.heap.length;\n    while (this.leftChild(i) < n) {\n      let smallest = this.leftChild(i);\n      const right = this.rightChild(i);\n      if (right < n && this.heap[right] < this.heap[smallest]) {\n        smallest = right;\n      }\n      if (this.heap[i] <= this.heap[smallest]) break;\n      this.swap(i, smallest);\n      i = smallest;\n    }\n  }\n}"
  },
  {
    "id": 9,
    "question": "What are the common sorting algorithms and their complexities?",
    "answer": "**Comparison-based sorts:**\n\n| Algorithm | Best | Average | Worst | Space | Stable |\n|-----------|------|---------|-------|-------|--------|\n| Bubble Sort | O(n) | O(n²) | O(n²) | O(1) | Yes |\n| Insertion Sort | O(n) | O(n²) | O(n²) | O(1) | Yes |\n| Selection Sort | O(n²) | O(n²) | O(n²) | O(1) | No |\n| Merge Sort | O(n log n) | O(n log n) | O(n log n) | O(n) | Yes |\n| Quick Sort | O(n log n) | O(n log n) | O(n²) | O(log n) | No |\n| Heap Sort | O(n log n) | O(n log n) | O(n log n) | O(1) | No |\n\n**Non-comparison sorts** (special cases, can beat O(n log n)):\n- Counting Sort: O(n + k), when range k is small\n- Radix Sort: O(d × n), d = digits\n- Bucket Sort: O(n + k), uniform distribution\n\n**Stable sort**: Equal elements maintain relative order",
    "example": "// Quick Sort - O(n log n) average, in-place\nfunction quickSort(arr, lo = 0, hi = arr.length - 1) {\n  if (lo < hi) {\n    const pivot = partition(arr, lo, hi);\n    quickSort(arr, lo, pivot - 1);\n    quickSort(arr, pivot + 1, hi);\n  }\n  return arr;\n}\n\nfunction partition(arr, lo, hi) {\n  const pivot = arr[hi];\n  let i = lo;\n  for (let j = lo; j < hi; j++) {\n    if (arr[j] < pivot) {\n      [arr[i], arr[j]] = [arr[j], arr[i]];\n      i++;\n    }\n  }\n  [arr[i], arr[hi]] = [arr[hi], arr[i]];\n  return i;\n}\n\n// Merge Sort - O(n log n) guaranteed, stable\nfunction mergeSort(arr) {\n  if (arr.length <= 1) return arr;\n  const mid = Math.floor(arr.length / 2);\n  const left = mergeSort(arr.slice(0, mid));\n  const right = mergeSort(arr.slice(mid));\n  return merge(left, right);\n}\n\nfunction merge(left, right) {\n  const result = [];\n  let i = 0, j = 0;\n  while (i < left.length && j < right.length) {\n    result.push(left[i] <= right[j] ? left[i++] : right[j++]);\n  }\n  return result.concat(left.slice(i)).concat(right.slice(j));\n}"
  },
  {
    "id": 10,
    "question": "What is a Graph and how do you represent it?",
    "answer": "A **Graph** G = (V, E) consists of vertices (nodes) and edges (connections).\n\n**Types:**\n- **Directed vs Undirected**: Edges have direction or not\n- **Weighted vs Unweighted**: Edges have costs or not\n- **Cyclic vs Acyclic**: Contains cycles or not (DAG = Directed Acyclic Graph)\n- **Connected vs Disconnected**: All vertices reachable or not\n\n**Representations:**\n\n**1. Adjacency Matrix**\n- 2D array, matrix[i][j] = 1 if edge exists\n- Space: O(V²)\n- Edge lookup: O(1)\n- Best for: Dense graphs, frequent edge queries\n\n**2. Adjacency List**\n- Array of lists, each vertex stores its neighbors\n- Space: O(V + E)\n- Edge lookup: O(degree)\n- Best for: Sparse graphs, traversals\n\n**3. Edge List**\n- List of (u, v, weight) tuples\n- Space: O(E)\n- Best for: Edge-centric algorithms (Kruskal's)",
    "example": "// Adjacency List representation\nclass Graph {\n  constructor() {\n    this.adjacencyList = new Map();\n  }\n\n  addVertex(vertex) {\n    if (!this.adjacencyList.has(vertex)) {\n      this.adjacencyList.set(vertex, []);\n    }\n  }\n\n  addEdge(v1, v2, weight = 1) {\n    // For undirected graph\n    this.adjacencyList.get(v1).push({ node: v2, weight });\n    this.adjacencyList.get(v2).push({ node: v1, weight });\n  }\n\n  getNeighbors(vertex) {\n    return this.adjacencyList.get(vertex) || [];\n  }\n}\n\n// Adjacency Matrix for dense graph\nclass GraphMatrix {\n  constructor(numVertices) {\n    this.matrix = Array(numVertices).fill(null)\n      .map(() => Array(numVertices).fill(0));\n  }\n\n  addEdge(v1, v2, weight = 1) {\n    this.matrix[v1][v2] = weight;\n    this.matrix[v2][v1] = weight; // undirected\n  }\n\n  hasEdge(v1, v2) {\n    return this.matrix[v1][v2] !== 0;\n  }\n}\n\n// Usage\nconst g = new Graph();\n['A', 'B', 'C', 'D'].forEach(v => g.addVertex(v));\ng.addEdge('A', 'B');\ng.addEdge('A', 'C');\ng.addEdge('B', 'D');"
  },
  {
    "id": 11,
    "question": "What is the Two Pointer technique?",
    "answer": "**Two Pointers** is a technique using two indices to traverse a data structure, often from opposite ends or at different speeds.\n\n**Common patterns:**\n\n**1. Opposite ends (converging)**\n- Start at beginning and end, move toward middle\n- Use: Pair sum, palindrome check, container problems\n\n**2. Same direction (fast/slow)**\n- Both start at beginning, move at different speeds\n- Use: Cycle detection, remove duplicates, linked list middle\n\n**3. Sliding window variant**\n- Left and right define a window\n- Use: Subarray problems, longest substring\n\n**Benefits:**\n- Reduces O(n²) brute force to O(n)\n- Constant extra space\n- Works on sorted arrays or when order doesn't matter\n\n**Requirements:**\n- Usually sorted array or specific structure\n- Some monotonic property to guide pointer movement",
    "example": "// Two Sum (sorted array) - Opposite ends\nfunction twoSum(arr, target) {\n  let left = 0, right = arr.length - 1;\n  while (left < right) {\n    const sum = arr[left] + arr[right];\n    if (sum === target) return [left, right];\n    if (sum < target) left++;\n    else right--;\n  }\n  return [-1, -1];\n}\n\n// Remove duplicates in-place - Same direction\nfunction removeDuplicates(arr) {\n  if (arr.length === 0) return 0;\n  let slow = 0;\n  for (let fast = 1; fast < arr.length; fast++) {\n    if (arr[fast] !== arr[slow]) {\n      slow++;\n      arr[slow] = arr[fast];\n    }\n  }\n  return slow + 1; // length of unique elements\n}\n\n// Cycle detection (Floyd's) - Fast/Slow\nfunction hasCycle(head) {\n  let slow = head, fast = head;\n  while (fast && fast.next) {\n    slow = slow.next;\n    fast = fast.next.next;\n    if (slow === fast) return true;\n  }\n  return false;\n}\n\n// Container with most water - Opposite ends\nfunction maxArea(heights) {\n  let left = 0, right = heights.length - 1, max = 0;\n  while (left < right) {\n    const area = Math.min(heights[left], heights[right]) * (right - left);\n    max = Math.max(max, area);\n    if (heights[left] < heights[right]) left++;\n    else right--;\n  }\n  return max;\n}"
  },
  {
    "id": 12,
    "question": "What is the Sliding Window technique?",
    "answer": "**Sliding Window** maintains a subset (window) of elements and slides it across the data structure to solve problems efficiently.\n\n**Types:**\n\n**1. Fixed-size window**\n- Window size is constant\n- Slide by adding right, removing left\n- Use: Max sum of k elements, averages\n\n**2. Variable-size window**\n- Expand right to include, shrink left when constraint violated\n- Use: Longest substring with k distinct chars, minimum window substring\n\n**Pattern:**\n1. Initialize window (often empty)\n2. Expand: Add right element\n3. Contract: Remove left elements while invalid\n4. Update answer\n5. Repeat until right reaches end\n\n**Benefits:**\n- O(n) instead of O(n²) brute force\n- Avoid recalculating entire window each time\n\n**Key insight**: Reuse computation from previous window",
    "example": "// Fixed window - Max sum of k consecutive elements\nfunction maxSumSubarray(arr, k) {\n  let windowSum = 0, maxSum = -Infinity;\n  \n  for (let i = 0; i < arr.length; i++) {\n    windowSum += arr[i];           // Add right\n    if (i >= k - 1) {\n      maxSum = Math.max(maxSum, windowSum);\n      windowSum -= arr[i - k + 1]; // Remove left\n    }\n  }\n  return maxSum;\n}\n\n// Variable window - Longest substring with k distinct chars\nfunction longestWithKDistinct(s, k) {\n  const charCount = new Map();\n  let left = 0, maxLen = 0;\n\n  for (let right = 0; right < s.length; right++) {\n    // Expand window\n    charCount.set(s[right], (charCount.get(s[right]) || 0) + 1);\n\n    // Shrink while invalid (more than k distinct)\n    while (charCount.size > k) {\n      charCount.set(s[left], charCount.get(s[left]) - 1);\n      if (charCount.get(s[left]) === 0) charCount.delete(s[left]);\n      left++;\n    }\n\n    // Update answer\n    maxLen = Math.max(maxLen, right - left + 1);\n  }\n  return maxLen;\n}\n\n// Example: longestWithKDistinct(\"araaci\", 2) → 4 (\"araa\")"
  },
  {
    "id": 13,
    "question": "How do you detect a cycle in a Linked List?",
    "answer": "**Floyd's Cycle Detection (Tortoise and Hare)**\n\nUse two pointers moving at different speeds:\n- Slow pointer: moves 1 step\n- Fast pointer: moves 2 steps\n\n**If cycle exists**: Fast will eventually meet slow inside the cycle\n**If no cycle**: Fast reaches end (null)\n\n**Why it works:**\n- If there's a cycle, fast enters first\n- Fast gains 1 step per iteration on slow\n- Eventually fast catches slow (like runners on a track)\n\n**Finding cycle start:**\n1. Detect cycle (fast meets slow)\n2. Reset one pointer to head\n3. Move both at same speed (1 step)\n4. They meet at cycle start\n\n**Mathematical proof**: Distance from head to cycle start equals distance from meeting point to cycle start (going around cycle)",
    "example": "// Detect if cycle exists - O(n) time, O(1) space\nfunction hasCycle(head) {\n  if (!head || !head.next) return false;\n  \n  let slow = head;\n  let fast = head;\n  \n  while (fast && fast.next) {\n    slow = slow.next;        // 1 step\n    fast = fast.next.next;   // 2 steps\n    if (slow === fast) return true;\n  }\n  return false;\n}\n\n// Find cycle start node\nfunction detectCycleStart(head) {\n  if (!head || !head.next) return null;\n  \n  let slow = head, fast = head;\n  \n  // Phase 1: Detect cycle\n  while (fast && fast.next) {\n    slow = slow.next;\n    fast = fast.next.next;\n    if (slow === fast) break;\n  }\n  \n  if (!fast || !fast.next) return null; // No cycle\n  \n  // Phase 2: Find cycle start\n  slow = head;\n  while (slow !== fast) {\n    slow = slow.next;\n    fast = fast.next;\n  }\n  return slow; // Cycle start\n}\n\n// Alternative: HashSet - O(n) time, O(n) space\nfunction hasCycleHashSet(head) {\n  const visited = new Set();\n  while (head) {\n    if (visited.has(head)) return true;\n    visited.add(head);\n    head = head.next;\n  }\n  return false;\n}"
  },
  {
    "id": 14,
    "question": "What is a Trie and when would you use it?",
    "answer": "A **Trie** (prefix tree) is a tree data structure for storing strings where each node represents a character.\n\n**Properties:**\n- Root is empty\n- Each path from root represents a prefix\n- Nodes can be marked as word endings\n- Common prefixes share nodes\n\n**Operations:**\n- Insert: O(m) where m = word length\n- Search: O(m)\n- Prefix search: O(m)\n- Delete: O(m)\n\n**Use cases:**\n- Autocomplete / typeahead\n- Spell checkers\n- IP routing (longest prefix match)\n- Word games (Boggle, Scrabble)\n- Dictionary implementation\n\n**Space**: O(ALPHABET_SIZE × m × n) worst case, but prefix sharing reduces this\n\n**Alternatives:**\n- Hash table: O(1) lookup but no prefix operations\n- BST: O(m log n) operations",
    "example": "class TrieNode {\n  constructor() {\n    this.children = new Map();\n    this.isEndOfWord = false;\n  }\n}\n\nclass Trie {\n  constructor() {\n    this.root = new TrieNode();\n  }\n\n  insert(word) {\n    let node = this.root;\n    for (const char of word) {\n      if (!node.children.has(char)) {\n        node.children.set(char, new TrieNode());\n      }\n      node = node.children.get(char);\n    }\n    node.isEndOfWord = true;\n  }\n\n  search(word) {\n    const node = this._traverse(word);\n    return node !== null && node.isEndOfWord;\n  }\n\n  startsWith(prefix) {\n    return this._traverse(prefix) !== null;\n  }\n\n  _traverse(str) {\n    let node = this.root;\n    for (const char of str) {\n      if (!node.children.has(char)) return null;\n      node = node.children.get(char);\n    }\n    return node;\n  }\n\n  // Autocomplete - find all words with prefix\n  autocomplete(prefix) {\n    const node = this._traverse(prefix);\n    if (!node) return [];\n    const results = [];\n    this._collectWords(node, prefix, results);\n    return results;\n  }\n\n  _collectWords(node, prefix, results) {\n    if (node.isEndOfWord) results.push(prefix);\n    for (const [char, child] of node.children) {\n      this._collectWords(child, prefix + char, results);\n    }\n  }\n}"
  },
  {
    "id": 15,
    "question": "Explain Dijkstra's Algorithm for shortest path.",
    "answer": "**Dijkstra's Algorithm** finds the shortest path from a source vertex to all other vertices in a weighted graph with non-negative edges.\n\n**Algorithm:**\n1. Initialize distances: source = 0, all others = ∞\n2. Add source to priority queue (min-heap)\n3. While queue not empty:\n   - Extract vertex with minimum distance\n   - For each neighbor, if new path is shorter, update distance and add to queue\n4. Return distances array\n\n**Time Complexity:**\n- With min-heap: O((V + E) log V)\n- With array (no heap): O(V²)\n\n**Limitations:**\n- Doesn't work with negative edge weights (use Bellman-Ford)\n- Greedy approach assumes shortest path to current node is final\n\n**Applications:**\n- GPS navigation\n- Network routing\n- Social network connections",
    "example": "function dijkstra(graph, start) {\n  const distances = new Map();\n  const previous = new Map();\n  const pq = new MinPriorityQueue(); // [distance, vertex]\n  \n  // Initialize\n  for (const vertex of graph.vertices) {\n    distances.set(vertex, vertex === start ? 0 : Infinity);\n    previous.set(vertex, null);\n  }\n  pq.enqueue([0, start]);\n\n  while (!pq.isEmpty()) {\n    const [dist, current] = pq.dequeue();\n    \n    // Skip if we've found a better path\n    if (dist > distances.get(current)) continue;\n\n    for (const { node: neighbor, weight } of graph.getNeighbors(current)) {\n      const newDist = distances.get(current) + weight;\n      \n      if (newDist < distances.get(neighbor)) {\n        distances.set(neighbor, newDist);\n        previous.set(neighbor, current);\n        pq.enqueue([newDist, neighbor]);\n      }\n    }\n  }\n\n  return { distances, previous };\n}\n\n// Reconstruct path from start to end\nfunction getPath(previous, end) {\n  const path = [];\n  let current = end;\n  while (current !== null) {\n    path.unshift(current);\n    current = previous.get(current);\n  }\n  return path;\n}\n\n// Usage:\n// const { distances, previous } = dijkstra(graph, 'A');\n// console.log(distances.get('D')); // Shortest distance to D\n// console.log(getPath(previous, 'D')); // Path from A to D"
  },
  {
    "id": 16,
    "question": "What is Recursion and how do you analyze recursive algorithms?",
    "answer": "**Recursion** is when a function calls itself to solve smaller instances of the same problem.\n\n**Components:**\n1. **Base case**: Terminating condition (stops recursion)\n2. **Recursive case**: Function calls itself with smaller input\n3. **Progress**: Each call moves toward base case\n\n**Analyzing recursion:**\n\n**Time complexity** - Use recurrence relations:\n- T(n) = T(n-1) + O(1) → O(n) (linear)\n- T(n) = T(n/2) + O(1) → O(log n) (binary search)\n- T(n) = 2T(n/2) + O(n) → O(n log n) (merge sort)\n- T(n) = 2T(n-1) + O(1) → O(2ⁿ) (naive fibonacci)\n\n**Space complexity**: O(depth of recursion) for call stack\n\n**Master Theorem** for T(n) = aT(n/b) + f(n):\n- Compare f(n) with n^(log_b(a))\n\n**Tail recursion**: Recursive call is last operation; can be optimized to iteration",
    "example": "// Factorial - Linear recursion O(n)\nfunction factorial(n) {\n  if (n <= 1) return 1;           // Base case\n  return n * factorial(n - 1);    // Recursive case\n}\n// T(n) = T(n-1) + O(1) → O(n)\n// Space: O(n) call stack\n\n// Binary Search - O(log n)\nfunction binarySearch(arr, target, lo = 0, hi = arr.length - 1) {\n  if (lo > hi) return -1;                    // Base case\n  const mid = Math.floor((lo + hi) / 2);\n  if (arr[mid] === target) return mid;       // Base case\n  if (arr[mid] < target)\n    return binarySearch(arr, target, mid + 1, hi);\n  return binarySearch(arr, target, lo, mid - 1);\n}\n// T(n) = T(n/2) + O(1) → O(log n)\n\n// Tree recursion (branching) - O(2^n)\nfunction fibNaive(n) {\n  if (n <= 1) return n;\n  return fibNaive(n - 1) + fibNaive(n - 2);  // Two recursive calls!\n}\n// T(n) = T(n-1) + T(n-2) + O(1) → O(2^n)\n\n// Tail recursion (optimizable)\nfunction factorialTail(n, acc = 1) {\n  if (n <= 1) return acc;\n  return factorialTail(n - 1, n * acc);  // Last operation is call\n}"
  },
  {
    "id": 17,
    "question": "What is Backtracking and when do you use it?",
    "answer": "**Backtracking** is a systematic way to search through all possible configurations by building solutions incrementally and abandoning (backtracking from) partial solutions that cannot lead to valid complete solutions.\n\n**Pattern:**\n1. Choose: Make a choice\n2. Explore: Recursively explore with that choice\n3. Unchoose: Undo the choice (backtrack)\n\n**When to use:**\n- Constraint satisfaction problems\n- Finding all solutions (or any solution)\n- Combinatorial problems\n- When brute force is too slow but pruning helps\n\n**Common problems:**\n- N-Queens\n- Sudoku solver\n- Permutations/Combinations\n- Word search in grid\n- Subset sum\n\n**Optimization**: Add constraints to prune branches early (pruning)\n\n**Time complexity**: Often O(n!) or O(2^n) worst case, but pruning reduces actual runtime",
    "example": "// Permutations - Generate all arrangements\nfunction permute(nums) {\n  const result = [];\n  \n  function backtrack(current, remaining) {\n    if (remaining.length === 0) {\n      result.push([...current]);  // Found a solution\n      return;\n    }\n    \n    for (let i = 0; i < remaining.length; i++) {\n      current.push(remaining[i]);           // Choose\n      const newRemaining = [...remaining.slice(0, i), ...remaining.slice(i + 1)];\n      backtrack(current, newRemaining);     // Explore\n      current.pop();                        // Unchoose (backtrack)\n    }\n  }\n  \n  backtrack([], nums);\n  return result;\n}\n\n// N-Queens - Place N queens on NxN board\nfunction solveNQueens(n) {\n  const result = [];\n  const board = Array(n).fill().map(() => Array(n).fill('.'));\n  \n  function isValid(row, col) {\n    for (let i = 0; i < row; i++) {\n      if (board[i][col] === 'Q') return false;  // Same column\n      if (col - (row - i) >= 0 && board[i][col - (row - i)] === 'Q') return false;\n      if (col + (row - i) < n && board[i][col + (row - i)] === 'Q') return false;\n    }\n    return true;\n  }\n  \n  function backtrack(row) {\n    if (row === n) {\n      result.push(board.map(r => r.join('')));\n      return;\n    }\n    for (let col = 0; col < n; col++) {\n      if (isValid(row, col)) {\n        board[row][col] = 'Q';    // Choose\n        backtrack(row + 1);       // Explore\n        board[row][col] = '.';    // Unchoose\n      }\n    }\n  }\n  \n  backtrack(0);\n  return result;\n}"
  },
  {
    "id": 18,
    "question": "What is the difference between a Tree and a Graph?",
    "answer": "**Tree:**\n- Connected, acyclic graph\n- Exactly one path between any two nodes\n- N nodes → N-1 edges\n- Has a root (in rooted trees)\n- Hierarchical structure\n- No need to track visited (no cycles)\n\n**Graph:**\n- Can have cycles\n- Can be disconnected\n- Multiple paths between nodes possible\n- No inherent root or hierarchy\n- Must track visited nodes in traversal\n- Can be directed or undirected\n\n**Key insight**: A tree is a special case of a graph (connected, acyclic)\n\n**Traversal differences:**\n- Tree: No visited tracking needed, natural recursive structure\n- Graph: Must track visited to avoid infinite loops in cycles\n\n**Common tree types:**\n- Binary tree, BST, AVL, Red-Black\n- N-ary tree, Trie\n- B-tree, B+ tree (databases)",
    "example": "// Tree traversal - No visited tracking needed\nfunction treeTraversal(root) {\n  if (!root) return;\n  console.log(root.val);           // Process node\n  treeTraversal(root.left);        // Left subtree\n  treeTraversal(root.right);       // Right subtree\n}\n\n// Graph DFS - MUST track visited\nfunction graphDFS(node, visited = new Set()) {\n  if (!node || visited.has(node)) return;\n  visited.add(node);               // Mark visited!\n  console.log(node.val);\n  for (const neighbor of node.neighbors) {\n    graphDFS(neighbor, visited);\n  }\n}\n\n// Tree has N-1 edges\n// Valid tree check: N nodes, N-1 edges, connected, no cycles\nfunction isValidTree(n, edges) {\n  if (edges.length !== n - 1) return false;  // Must have N-1 edges\n  \n  // Check if connected using Union-Find or DFS\n  const adj = Array.from({ length: n }, () => []);\n  for (const [u, v] of edges) {\n    adj[u].push(v);\n    adj[v].push(u);\n  }\n  \n  const visited = new Set();\n  function dfs(node) {\n    visited.add(node);\n    for (const neighbor of adj[node]) {\n      if (!visited.has(neighbor)) dfs(neighbor);\n    }\n  }\n  \n  dfs(0);\n  return visited.size === n;  // All nodes reachable = connected\n}"
  },
  {
    "id": 19,
    "question": "What is Union-Find (Disjoint Set Union)?",
    "answer": "**Union-Find** is a data structure that tracks elements partitioned into disjoint (non-overlapping) sets.\n\n**Operations:**\n- **Find(x)**: Return the representative (root) of x's set\n- **Union(x, y)**: Merge the sets containing x and y\n\n**Optimizations:**\n1. **Path compression**: During Find, make nodes point directly to root\n2. **Union by rank/size**: Attach smaller tree under larger tree's root\n\n**With both optimizations:**\n- Nearly O(1) amortized per operation\n- Technically O(α(n)) where α is inverse Ackermann function\n\n**Use cases:**\n- Detect cycles in undirected graph\n- Kruskal's MST algorithm\n- Connected components\n- Network connectivity\n- Percolation problems",
    "example": "class UnionFind {\n  constructor(n) {\n    this.parent = Array.from({ length: n }, (_, i) => i);\n    this.rank = Array(n).fill(0);\n    this.count = n;  // Number of components\n  }\n\n  find(x) {\n    if (this.parent[x] !== x) {\n      this.parent[x] = this.find(this.parent[x]);  // Path compression\n    }\n    return this.parent[x];\n  }\n\n  union(x, y) {\n    const rootX = this.find(x);\n    const rootY = this.find(y);\n    \n    if (rootX === rootY) return false;  // Already in same set\n    \n    // Union by rank\n    if (this.rank[rootX] < this.rank[rootY]) {\n      this.parent[rootX] = rootY;\n    } else if (this.rank[rootX] > this.rank[rootY]) {\n      this.parent[rootY] = rootX;\n    } else {\n      this.parent[rootY] = rootX;\n      this.rank[rootX]++;\n    }\n    this.count--;\n    return true;\n  }\n\n  connected(x, y) {\n    return this.find(x) === this.find(y);\n  }\n}\n\n// Detect cycle in undirected graph\nfunction hasCycle(n, edges) {\n  const uf = new UnionFind(n);\n  for (const [u, v] of edges) {\n    if (uf.connected(u, v)) return true;  // Already connected = cycle\n    uf.union(u, v);\n  }\n  return false;\n}\n\n// Count connected components\nfunction countComponents(n, edges) {\n  const uf = new UnionFind(n);\n  for (const [u, v] of edges) uf.union(u, v);\n  return uf.count;\n}"
  },
  {
    "id": 20,
    "question": "What is the difference between Greedy algorithms and Dynamic Programming?",
    "answer": "**Greedy Algorithm:**\n- Makes locally optimal choice at each step\n- Never reconsiders choices (no backtracking)\n- Faster and simpler when applicable\n- Doesn't always give optimal solution\n- Must prove greedy choice property\n\n**Dynamic Programming:**\n- Considers all possible choices\n- Stores results of subproblems (memoization/tabulation)\n- Guarantees optimal solution (if applicable)\n- More complex, uses more memory\n- Requires optimal substructure + overlapping subproblems\n\n**Key difference:**\n- Greedy: \"Take the best option now\"\n- DP: \"Consider all options, combine optimal sub-solutions\"\n\n**When greedy works:**\n- Interval scheduling\n- Huffman coding\n- Dijkstra (non-negative weights)\n- Minimum spanning tree (Prim's, Kruskal's)\n\n**When you need DP:**\n- 0/1 Knapsack\n- Longest common subsequence\n- Edit distance\n- Coin change (minimum coins)",
    "example": "// COIN CHANGE - Greedy vs DP\n\n// Greedy approach - Doesn't always work!\nfunction coinChangeGreedy(coins, amount) {\n  coins.sort((a, b) => b - a);  // Largest first\n  let count = 0;\n  for (const coin of coins) {\n    count += Math.floor(amount / coin);\n    amount %= coin;\n  }\n  return amount === 0 ? count : -1;\n}\n// Fails: coins=[1,3,4], amount=6\n// Greedy: 4+1+1=3 coins\n// Optimal: 3+3=2 coins\n\n// DP approach - Always optimal\nfunction coinChangeDP(coins, amount) {\n  const dp = Array(amount + 1).fill(Infinity);\n  dp[0] = 0;\n  \n  for (let i = 1; i <= amount; i++) {\n    for (const coin of coins) {\n      if (coin <= i) {\n        dp[i] = Math.min(dp[i], dp[i - coin] + 1);\n      }\n    }\n  }\n  return dp[amount] === Infinity ? -1 : dp[amount];\n}\n\n// INTERVAL SCHEDULING - Greedy works!\nfunction maxMeetings(intervals) {\n  intervals.sort((a, b) => a[1] - b[1]);  // Sort by end time\n  let count = 0, lastEnd = -Infinity;\n  \n  for (const [start, end] of intervals) {\n    if (start >= lastEnd) {  // Greedy: take earliest ending\n      count++;\n      lastEnd = end;\n    }\n  }\n  return count;\n}\n// Greedy works because taking earliest ending maximizes room for future"
  }
]
