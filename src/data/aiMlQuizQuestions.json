[
  {
    "id": 1,
    "question": "What is the difference between supervised and unsupervised learning?",
    "answer": "**Supervised learning** uses labeled data where the algorithm learns to map inputs to known outputs (e.g., classification, regression). The model is trained with input-output pairs.\n\n**Unsupervised learning** works with unlabeled data to find hidden patterns or structures (e.g., clustering, dimensionality reduction). The model discovers relationships without predefined labels.",
    "example": "# Supervised: Predicting house prices (labeled)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)  # y_train contains actual prices\n\n# Unsupervised: Customer segmentation (unlabeled)\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(X)  # No labels needed"
  },
  {
    "id": 2,
    "question": "What is overfitting and how can you prevent it?",
    "answer": "**Overfitting** occurs when a model learns the training data too well, including noise and outliers, resulting in poor generalization to new data. The model has high variance and low bias.\n\n**Prevention techniques:**\n- Cross-validation\n- Regularization (L1/L2)\n- Early stopping\n- Dropout (for neural networks)\n- Data augmentation\n- Reducing model complexity\n- Ensemble methods",
    "example": "# L2 Regularization (Ridge)\nfrom sklearn.linear_model import Ridge\nmodel = Ridge(alpha=1.0)  # alpha controls regularization strength\n\n# Dropout in neural networks\nimport torch.nn as nn\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(100, 50)\n        self.dropout = nn.Dropout(0.5)  # 50% dropout\n        self.fc2 = nn.Linear(50, 10)\n    \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)"
  },
  {
    "id": 3,
    "question": "Explain the bias-variance tradeoff.",
    "answer": "The **bias-variance tradeoff** is a fundamental concept describing the balance between two sources of error:\n\n**Bias**: Error from oversimplified assumptions. High bias leads to underfitting (model misses patterns).\n\n**Variance**: Error from sensitivity to training data fluctuations. High variance leads to overfitting (model captures noise).\n\n**Total Error** = Bias² + Variance + Irreducible Error\n\nThe goal is finding the sweet spot where both are minimized.",
    "example": "# High Bias (Underfitting) - Too simple\nfrom sklearn.linear_model import LinearRegression\nsimple_model = LinearRegression()  # May miss complex patterns\n\n# High Variance (Overfitting) - Too complex\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model = DecisionTreeRegressor(max_depth=None)  # Memorizes data\n\n# Balanced - Regularized model\nfrom sklearn.ensemble import RandomForestRegressor\nbalanced_model = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=10,\n    min_samples_leaf=5\n)"
  },
  {
    "id": 4,
    "question": "What are precision, recall, and F1-score? When would you prioritize one over another?",
    "answer": "**Precision** = TP / (TP + FP) — Of all positive predictions, how many were correct? Prioritize when false positives are costly (spam detection).\n\n**Recall** = TP / (TP + FN) — Of all actual positives, how many were found? Prioritize when false negatives are costly (cancer detection).\n\n**F1-Score** = 2 × (Precision × Recall) / (Precision + Recall) — Harmonic mean balancing both. Use when you need a single metric and classes are imbalanced.",
    "example": "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n\ny_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\ny_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n\nprint(f\"Precision: {precision_score(y_true, y_pred):.2f}\")  # 0.80\nprint(f\"Recall: {recall_score(y_true, y_pred):.2f}\")        # 0.67\nprint(f\"F1-Score: {f1_score(y_true, y_pred):.2f}\")          # 0.73\n\n# Full report\nprint(classification_report(y_true, y_pred))"
  },
  {
    "id": 5,
    "question": "What is gradient descent and what are its variants?",
    "answer": "**Gradient descent** is an optimization algorithm that iteratively updates parameters by moving in the direction of steepest descent (negative gradient) to minimize a loss function.\n\n**Variants:**\n- **Batch GD**: Uses entire dataset per update. Stable but slow.\n- **Stochastic GD (SGD)**: Uses one sample per update. Fast but noisy.\n- **Mini-batch GD**: Uses small batches. Balances speed and stability.\n- **Momentum**: Accelerates convergence using velocity.\n- **Adam**: Adaptive learning rates per parameter with momentum.",
    "example": "import torch.optim as optim\n\n# Standard SGD\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# SGD with Momentum\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n# Adam (most commonly used)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()"
  },
  {
    "id": 6,
    "question": "What is the difference between bagging and boosting?",
    "answer": "Both are ensemble methods combining multiple models:\n\n**Bagging (Bootstrap Aggregating)**:\n- Trains models in parallel on random subsets (with replacement)\n- Reduces variance\n- Models are independent\n- Example: Random Forest\n\n**Boosting**:\n- Trains models sequentially, each correcting predecessor's errors\n- Reduces bias\n- Models are dependent\n- Examples: AdaBoost, Gradient Boosting, XGBoost",
    "example": "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# Bagging - Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_features='sqrt',\n    bootstrap=True  # Bagging enabled\n)\n\n# Boosting - Gradient Boosting\ngb = GradientBoostingClassifier(\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=3\n)\n\n# XGBoost (optimized boosting)\nxgb = XGBClassifier(\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=3\n)"
  },
  {
    "id": 7,
    "question": "Explain the architecture of a Transformer and why self-attention is important.",
    "answer": "**Transformer architecture** (introduced in 'Attention Is All You Need'):\n- **Encoder**: Processes input sequence with self-attention + feed-forward layers\n- **Decoder**: Generates output with masked self-attention + cross-attention\n- **Positional encoding**: Adds sequence order information\n\n**Self-attention importance**:\n- Captures long-range dependencies regardless of distance\n- Enables parallel processing (unlike RNNs)\n- Each position attends to all positions in input\n- Foundation for BERT, GPT, and modern LLMs",
    "example": "import torch\nimport torch.nn as nn\n\nclass SelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super().__init__()\n        self.multihead_attn = nn.MultiheadAttention(\n            embed_dim=embed_dim,\n            num_heads=num_heads\n        )\n    \n    def forward(self, x):\n        # x shape: (seq_len, batch, embed_dim)\n        # Self-attention: query, key, value are all x\n        attn_output, attn_weights = self.multihead_attn(x, x, x)\n        return attn_output, attn_weights\n\n# Using PyTorch's TransformerEncoder\nencoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\ntransformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)"
  },
  {
    "id": 8,
    "question": "What is backpropagation and how does it work?",
    "answer": "**Backpropagation** is the algorithm for computing gradients of the loss function with respect to network weights, enabling gradient descent optimization.\n\n**How it works:**\n1. **Forward pass**: Compute predictions and loss\n2. **Backward pass**: Apply chain rule to compute gradients layer by layer, from output to input\n3. **Update weights**: Adjust parameters using gradients\n\nThe chain rule allows decomposing complex gradient computations into simpler local gradients.",
    "example": "import torch\nimport torch.nn as nn\n\n# Simple network\nmodel = nn.Sequential(\n    nn.Linear(10, 5),\n    nn.ReLU(),\n    nn.Linear(5, 1)\n)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Training step\nx = torch.randn(32, 10)\ny = torch.randn(32, 1)\n\n# Forward pass\npredictions = model(x)\nloss = criterion(predictions, y)\n\n# Backward pass (computes gradients via chain rule)\nloss.backward()\n\n# Check gradients\nprint(model[0].weight.grad.shape)  # Gradients for first layer\n\n# Update weights\noptimizer.step()"
  },
  {
    "id": 9,
    "question": "What are word embeddings and how do Word2Vec and contextual embeddings differ?",
    "answer": "**Word embeddings** are dense vector representations capturing semantic meaning of words.\n\n**Word2Vec** (static embeddings):\n- Fixed vector per word regardless of context\n- Trained via CBOW or Skip-gram\n- 'bank' has same embedding in 'river bank' and 'bank account'\n\n**Contextual embeddings** (BERT, GPT):\n- Dynamic vectors based on surrounding context\n- Same word gets different embeddings in different sentences\n- Better capture polysemy and nuance",
    "example": "# Word2Vec - Static embeddings\nfrom gensim.models import Word2Vec\nsentences = [[\"cat\", \"sat\", \"mat\"], [\"dog\", \"ran\", \"fast\"]]\nmodel = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\nvector = model.wv['cat']  # Same vector always\n\n# BERT - Contextual embeddings\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Same word, different contexts\ntext1 = \"I deposited money at the bank\"\ntext2 = \"I sat by the river bank\"\n\nfor text in [text1, text2]:\n    inputs = tokenizer(text, return_tensors='pt')\n    outputs = model(**inputs)\n    # 'bank' embedding differs based on context"
  },
  {
    "id": 10,
    "question": "How do you handle imbalanced datasets in classification?",
    "answer": "**Techniques for imbalanced data:**\n\n**Data-level:**\n- Oversampling minority class (SMOTE)\n- Undersampling majority class\n- Synthetic data generation\n\n**Algorithm-level:**\n- Class weights in loss function\n- Cost-sensitive learning\n- Anomaly detection approach\n\n**Evaluation:**\n- Use precision, recall, F1, AUC-ROC instead of accuracy\n- Stratified cross-validation",
    "example": "from imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# SMOTE oversampling\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Class weights\nclass_weights = compute_class_weight(\n    'balanced', \n    classes=np.unique(y), \n    y=y\n)\nweight_dict = dict(zip(np.unique(y), class_weights))\n\n# Apply weights in model\nmodel = RandomForestClassifier(class_weight='balanced')\n\n# Or in PyTorch loss\nimport torch.nn as nn\nweights = torch.tensor([1.0, 10.0])  # Higher weight for minority\ncriterion = nn.CrossEntropyLoss(weight=weights)"
  },
  {
    "id": 11,
    "question": "What is cross-validation and why is k-fold preferred over a simple train/test split?",
    "answer": "**Cross-validation** is a technique to assess model generalization by training and evaluating on different data subsets.\n\n**K-fold cross-validation:**\n1. Split data into k equal folds\n2. Train on k-1 folds, validate on remaining fold\n3. Repeat k times, rotating the validation fold\n4. Average results across all folds\n\n**Advantages over simple split:**\n- Uses all data for both training and validation\n- More reliable performance estimate\n- Reduces variance from lucky/unlucky splits\n- Better for smaller datasets",
    "example": "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\n# Simple k-fold\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\nprint(f\"Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})\")\n\n# Stratified k-fold (maintains class distribution)\nstrat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X, y, cv=strat_kfold, scoring='f1')\n\n# Multiple metrics\nfrom sklearn.model_selection import cross_validate\nresults = cross_validate(\n    model, X, y, cv=5,\n    scoring=['accuracy', 'precision', 'recall', 'f1']\n)"
  },
  {
    "id": 12,
    "question": "Explain the difference between generative and discriminative models.",
    "answer": "**Discriminative models** learn the decision boundary P(y|x) directly:\n- Focus on distinguishing between classes\n- Examples: Logistic Regression, SVM, Neural Networks\n- Generally better for classification when you have enough data\n\n**Generative models** learn the joint distribution P(x,y) or P(x):\n- Model how data is generated\n- Can generate new samples\n- Examples: Naive Bayes, GMM, VAE, GANs, GPT\n- Better with limited data, can handle missing features",
    "example": "# Discriminative - Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\ndiscrim_model = LogisticRegression()\ndiscrim_model.fit(X_train, y_train)\nprob = discrim_model.predict_proba(X_test)  # P(y|x) directly\n\n# Generative - Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\ngen_model = GaussianNB()\ngen_model.fit(X_train, y_train)\n# Internally models P(x|y) and P(y), uses Bayes' theorem\n\n# Generative - VAE for image generation\nclass VAE(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = Encoder()  # q(z|x)\n        self.decoder = Decoder()  # p(x|z)\n    \n    def generate(self, num_samples):\n        z = torch.randn(num_samples, latent_dim)\n        return self.decoder(z)  # Generate new samples"
  },
  {
    "id": 13,
    "question": "What is batch normalization and why is it used?",
    "answer": "**Batch normalization** normalizes layer inputs by re-centering and re-scaling across a mini-batch.\n\n**Benefits:**\n- Reduces internal covariate shift\n- Allows higher learning rates\n- Acts as regularization\n- Faster convergence\n- Reduces sensitivity to initialization\n\n**Formula:** Normalize to zero mean, unit variance, then scale (γ) and shift (β) with learnable parameters.",
    "example": "import torch.nn as nn\n\n# In CNNs - BatchNorm2d\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n        self.bn = nn.BatchNorm2d(out_ch)  # After conv\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))\n\n# In fully connected - BatchNorm1d\nmodel = nn.Sequential(\n    nn.Linear(100, 50),\n    nn.BatchNorm1d(50),\n    nn.ReLU(),\n    nn.Linear(50, 10)\n)\n\n# Layer Normalization (for transformers/RNNs)\nln = nn.LayerNorm(normalized_shape=512)  # Normalizes across features"
  },
  {
    "id": 14,
    "question": "How do you design a feature store for ML systems in production?",
    "answer": "**Feature store** is a centralized repository for storing, managing, and serving ML features.\n\n**Key components:**\n- **Offline store**: Batch features for training (data warehouse)\n- **Online store**: Low-latency features for inference (Redis, DynamoDB)\n- **Feature registry**: Metadata, lineage, documentation\n- **Transformation engine**: Feature computation pipelines\n\n**Design considerations:**\n- Point-in-time correctness (avoid data leakage)\n- Feature freshness requirements\n- Consistency between training and serving\n- Feature versioning and monitoring",
    "example": "# Using Feast feature store\nfrom feast import FeatureStore, Entity, Feature, FeatureView\nfrom feast.types import Float32, Int64\n\n# Define entity\nuser = Entity(name=\"user_id\", value_type=Int64)\n\n# Define feature view\nuser_features = FeatureView(\n    name=\"user_features\",\n    entities=[\"user_id\"],\n    features=[\n        Feature(name=\"avg_purchase_amount\", dtype=Float32),\n        Feature(name=\"total_orders\", dtype=Int64),\n    ],\n    ttl=timedelta(days=1),\n    online=True,\n)\n\n# Retrieve for training (point-in-time join)\nstore = FeatureStore(repo_path=\".\")\ntraining_df = store.get_historical_features(\n    entity_df=entity_df,\n    features=[\"user_features:avg_purchase_amount\", \"user_features:total_orders\"]\n).to_df()\n\n# Retrieve for online inference\nonline_features = store.get_online_features(\n    features=[\"user_features:avg_purchase_amount\"],\n    entity_rows=[{\"user_id\": 123}]\n).to_dict()"
  },
  {
    "id": 15,
    "question": "What is the vanishing gradient problem and how do modern architectures address it?",
    "answer": "**Vanishing gradient problem**: In deep networks, gradients become exponentially smaller as they backpropagate through layers, preventing early layers from learning.\n\n**Causes:**\n- Sigmoid/tanh activations saturate (gradient → 0)\n- Many multiplications of small values\n\n**Solutions:**\n- **ReLU activation**: Non-saturating, gradient = 1 for positive values\n- **Residual connections**: Skip connections allow gradient flow\n- **LSTM/GRU**: Gating mechanisms preserve gradients\n- **Batch normalization**: Maintains healthy gradient magnitudes\n- **Proper initialization**: Xavier, He initialization",
    "example": "import torch.nn as nn\n\n# ResNet-style skip connection\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(channels)\n    \n    def forward(self, x):\n        residual = x  # Skip connection\n        out = nn.functional.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += residual  # Add skip connection\n        return nn.functional.relu(out)\n\n# He initialization for ReLU networks\ndef init_weights(m):\n    if isinstance(m, nn.Linear):\n        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')"
  },
  {
    "id": 16,
    "question": "Explain how you would implement A/B testing for ML models in production.",
    "answer": "**A/B testing for ML models** compares a new model (treatment) against the current model (control) using statistical methods.\n\n**Implementation steps:**\n1. **Traffic splitting**: Randomly assign users to control/treatment\n2. **Metric definition**: Primary (conversion) and guardrail metrics\n3. **Sample size calculation**: Determine required users for statistical power\n4. **Run experiment**: Collect data over sufficient time\n5. **Statistical analysis**: Hypothesis testing, confidence intervals\n6. **Decision**: Ship, iterate, or rollback\n\n**Considerations:**\n- Novelty effects\n- Network effects\n- Multiple comparisons correction",
    "example": "import numpy as np\nfrom scipy import stats\n\n# Simple A/B test analysis\ndef ab_test_analysis(control_conversions, control_total,\n                     treatment_conversions, treatment_total):\n    # Conversion rates\n    p_control = control_conversions / control_total\n    p_treatment = treatment_conversions / treatment_total\n    \n    # Pooled probability\n    p_pooled = (control_conversions + treatment_conversions) / \\\n               (control_total + treatment_total)\n    \n    # Standard error\n    se = np.sqrt(p_pooled * (1-p_pooled) * \n                 (1/control_total + 1/treatment_total))\n    \n    # Z-score and p-value\n    z_score = (p_treatment - p_control) / se\n    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n    \n    # Lift\n    lift = (p_treatment - p_control) / p_control * 100\n    \n    return {\n        'control_rate': p_control,\n        'treatment_rate': p_treatment,\n        'lift': f\"{lift:.2f}%\",\n        'p_value': p_value,\n        'significant': p_value < 0.05\n    }"
  },
  {
    "id": 17,
    "question": "What are the key considerations when deploying LLMs to production?",
    "answer": "**Key LLM deployment considerations:**\n\n**Infrastructure:**\n- GPU memory requirements (model size)\n- Batching strategies for throughput\n- Quantization (INT8, INT4) for efficiency\n- Model sharding across GPUs\n\n**Performance:**\n- Latency requirements and KV-cache optimization\n- Streaming responses for UX\n- Request queuing and rate limiting\n\n**Quality & Safety:**\n- Prompt injection protection\n- Output filtering and guardrails\n- Hallucination mitigation (RAG)\n- Monitoring for drift and quality\n\n**Cost:**\n- Token usage optimization\n- Caching common responses\n- Model selection (smaller models for simpler tasks)",
    "example": "# vLLM for efficient LLM serving\nfrom vllm import LLM, SamplingParams\n\n# Load model with quantization\nllm = LLM(\n    model=\"meta-llama/Llama-2-7b-chat-hf\",\n    quantization=\"awq\",  # 4-bit quantization\n    tensor_parallel_size=2,  # Shard across 2 GPUs\n    gpu_memory_utilization=0.9\n)\n\n# Batch inference for throughput\nsampling_params = SamplingParams(\n    temperature=0.7,\n    max_tokens=256,\n    stop=[\"</s>\"]\n)\n\nprompts = [\"What is ML?\", \"Explain transformers\"]\noutputs = llm.generate(prompts, sampling_params)\n\n# Streaming with FastAPI\nfrom fastapi.responses import StreamingResponse\n\nasync def stream_response(prompt: str):\n    async for chunk in llm.generate_stream(prompt):\n        yield chunk.text"
  },
  {
    "id": 18,
    "question": "Explain Retrieval-Augmented Generation (RAG) and its architecture.",
    "answer": "**RAG** combines retrieval systems with generative models to ground responses in external knowledge.\n\n**Architecture:**\n1. **Indexing**: Chunk documents, create embeddings, store in vector DB\n2. **Retrieval**: Query embedding → find similar chunks\n3. **Augmentation**: Inject retrieved context into prompt\n4. **Generation**: LLM generates response using context\n\n**Benefits:**\n- Reduces hallucinations\n- Enables knowledge updates without retraining\n- Provides source attribution\n- More cost-effective than fine-tuning for domain knowledge",
    "example": "from langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import RetrievalQA\n\n# 1. Index documents\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200\n)\nchunks = text_splitter.split_documents(documents)\n\n# 2. Create vector store\nembeddings = OpenAIEmbeddings()\nvectorstore = Chroma.from_documents(chunks, embeddings)\n\n# 3. Create RAG chain\nllm = ChatOpenAI(model=\"gpt-4\")\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever(\n        search_kwargs={\"k\": 4}  # Top 4 chunks\n    ),\n    return_source_documents=True\n)\n\n# 4. Query\nresult = qa_chain({\"query\": \"What is our refund policy?\"})\nprint(result[\"result\"])\nprint(result[\"source_documents\"])"
  },
  {
    "id": 19,
    "question": "How do you implement model monitoring and detect data/model drift in production?",
    "answer": "**Model monitoring** tracks model health and detects degradation in production.\n\n**Types of drift:**\n- **Data drift**: Input distribution changes (P(X) shifts)\n- **Concept drift**: Relationship between input and output changes (P(Y|X) shifts)\n- **Prediction drift**: Model output distribution changes\n\n**Detection methods:**\n- Statistical tests (KS test, chi-square, PSI)\n- Distribution comparisons over time windows\n- Performance monitoring against labeled samples\n\n**Key metrics:**\n- Input feature distributions\n- Prediction distributions\n- Latency, throughput, error rates\n- Business metrics (conversion, engagement)",
    "example": "import numpy as np\nfrom scipy import stats\nfrom evidently import ColumnMapping\nfrom evidently.report import Report\nfrom evidently.metrics import DataDriftTable, DatasetDriftMetric\n\n# Population Stability Index (PSI)\ndef calculate_psi(expected, actual, bins=10):\n    expected_hist, bin_edges = np.histogram(expected, bins=bins)\n    actual_hist, _ = np.histogram(actual, bins=bin_edges)\n    \n    expected_pct = expected_hist / len(expected) + 0.0001\n    actual_pct = actual_hist / len(actual) + 0.0001\n    \n    psi = np.sum((actual_pct - expected_pct) * np.log(actual_pct / expected_pct))\n    return psi  # PSI > 0.2 indicates significant drift\n\n# Using Evidently for drift detection\nreport = Report(metrics=[\n    DatasetDriftMetric(),\n    DataDriftTable()\n])\n\nreport.run(\n    reference_data=training_data,\n    current_data=production_data,\n    column_mapping=ColumnMapping()\n)\nreport.save_html(\"drift_report.html\")"
  },
  {
    "id": 20,
    "question": "What is fine-tuning vs prompt engineering vs RAG, and when should you use each?",
    "answer": "**Prompt Engineering:**\n- Craft instructions/examples in the prompt\n- Use when: Quick iteration, general tasks, no training data\n- Pros: No training cost, instant changes\n- Cons: Limited by context window, inconsistent\n\n**RAG (Retrieval-Augmented Generation):**\n- Retrieve relevant docs and inject into context\n- Use when: Domain knowledge needed, data changes frequently, need citations\n- Pros: Up-to-date knowledge, attributable\n- Cons: Retrieval quality dependent, added latency\n\n**Fine-tuning:**\n- Train model on task-specific data\n- Use when: Specific style/format needed, consistent behavior required, have quality training data\n- Pros: Consistent outputs, smaller context needed\n- Cons: Training cost, can forget general knowledge",
    "example": "# Decision framework:\n\n# 1. PROMPT ENGINEERING - Start here\n#    - \"Summarize this in 3 bullet points\"\n#    - Few-shot examples in prompt\n#    - Works for ~60% of use cases\n\n# 2. RAG - When external knowledge needed\nif needs_domain_knowledge or data_changes_frequently:\n    use_rag = True\n    # Example: Customer support with product docs\n    # Example: Legal research with case law\n\n# 3. FINE-TUNING - When behavior/format matters\nif (need_consistent_style or \n    specific_output_format or \n    have_quality_labeled_data):\n    use_fine_tuning = True\n    # Example: Code completion in company style\n    # Example: Medical report generation\n\n# 4. COMBINATION - Often best\n# Fine-tuned model + RAG for domain-specific Q&A\n# Example: Fine-tune for tone, RAG for knowledge"
  }
]
